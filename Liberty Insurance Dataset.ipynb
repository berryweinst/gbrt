{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBRT_DIR_PATH = '/home/pereldamian/PycharmProjects/gbrt_new'\n",
    "TRAIN_DATA_PATH = './data_liberty/train.csv'\n",
    "LABEL_NAME = 'Hazard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GBRT imports\n",
    "sys.path.insert(0, GBRT_DIR_PATH)\n",
    "from data_utils import parse_data\n",
    "from gbrt_algorithm import gbrt\n",
    "from feature_selection import ensemble_feature_importance\n",
    "from main import HParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = parse_data(TRAIN_DATA_PATH, label_name=LABEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hazard</th>\n",
       "      <th>T1_V1</th>\n",
       "      <th>T1_V2</th>\n",
       "      <th>T1_V3</th>\n",
       "      <th>T1_V4</th>\n",
       "      <th>T1_V5</th>\n",
       "      <th>T1_V6</th>\n",
       "      <th>T1_V7</th>\n",
       "      <th>T1_V8</th>\n",
       "      <th>T1_V9</th>\n",
       "      <th>...</th>\n",
       "      <th>T2_V6</th>\n",
       "      <th>T2_V7</th>\n",
       "      <th>T2_V8</th>\n",
       "      <th>T2_V9</th>\n",
       "      <th>T2_V10</th>\n",
       "      <th>T2_V11</th>\n",
       "      <th>T2_V12</th>\n",
       "      <th>T2_V13</th>\n",
       "      <th>T2_V14</th>\n",
       "      <th>T2_V15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hazard  T1_V1  T1_V2  T1_V3 T1_V4 T1_V5 T1_V6 T1_V7 T1_V8 T1_V9   ...    \\\n",
       "Id                                                                    ...     \n",
       "1        1     15      3      2     N     B     N     B     B     D   ...     \n",
       "2        4     16     14      5     H     B     N     B     B     C   ...     \n",
       "3        1     10     10      5     N     K     N     B     B     E   ...     \n",
       "4        1     18     18      5     N     K     N     B     B     E   ...     \n",
       "5        1     13     19      5     N     H     N     B     B     E   ...     \n",
       "\n",
       "    T2_V6 T2_V7 T2_V8  T2_V9  T2_V10 T2_V11 T2_V12 T2_V13  T2_V14  T2_V15  \n",
       "Id                                                                         \n",
       "1       2    37     1     11       6      Y      N      E       2       2  \n",
       "2       2    22     1     18       5      Y      Y      E       2       1  \n",
       "3       6    37     2     14       6      Y      Y      E       6       1  \n",
       "4       2    25     1      1       6      Y      N      C       2       6  \n",
       "5       1    22     1      2       7      N      N      E       1       1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50999 entries, 1 to 101999\n",
      "Data columns (total 33 columns):\n",
      "Hazard    50999 non-null int64\n",
      "T1_V1     50999 non-null int64\n",
      "T1_V2     50999 non-null int64\n",
      "T1_V3     50999 non-null int64\n",
      "T1_V4     50999 non-null object\n",
      "T1_V5     50999 non-null object\n",
      "T1_V6     50999 non-null object\n",
      "T1_V7     50999 non-null object\n",
      "T1_V8     50999 non-null object\n",
      "T1_V9     50999 non-null object\n",
      "T1_V10    50999 non-null int64\n",
      "T1_V11    50999 non-null object\n",
      "T1_V12    50999 non-null object\n",
      "T1_V13    50999 non-null int64\n",
      "T1_V14    50999 non-null int64\n",
      "T1_V15    50999 non-null object\n",
      "T1_V16    50999 non-null object\n",
      "T1_V17    50999 non-null object\n",
      "T2_V1     50999 non-null int64\n",
      "T2_V2     50999 non-null int64\n",
      "T2_V3     50999 non-null object\n",
      "T2_V4     50999 non-null int64\n",
      "T2_V5     50999 non-null object\n",
      "T2_V6     50999 non-null int64\n",
      "T2_V7     50999 non-null int64\n",
      "T2_V8     50999 non-null int64\n",
      "T2_V9     50999 non-null int64\n",
      "T2_V10    50999 non-null int64\n",
      "T2_V11    50999 non-null object\n",
      "T2_V12    50999 non-null object\n",
      "T2_V13    50999 non-null object\n",
      "T2_V14    50999 non-null int64\n",
      "T2_V15    50999 non-null int64\n",
      "dtypes: int64(17), object(16)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Training models with different hyper parameters.\n",
    "All models logs are saved in models_data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 3 0.6 10\n",
      "Add tree number 1\n",
      "Train mean loss is: 18.311351382073223\n",
      "Test mean loss is: 17.171282341927597\n",
      "Add tree number 2\n",
      "Train mean loss is: 15.835926218882854\n",
      "Test mean loss is: 14.905861743896436\n",
      "Add tree number 3\n",
      "Train mean loss is: 15.227401620666102\n",
      "Test mean loss is: 14.444788554852737\n",
      "Add tree number 4\n",
      "Train mean loss is: 15.028155236157838\n",
      "Test mean loss is: 14.285466304803784\n",
      "Add tree number 5\n",
      "Train mean loss is: 14.923569883740658\n",
      "Test mean loss is: 14.210159060624514\n",
      "Add tree number 6\n",
      "Train mean loss is: 14.816602846503809\n",
      "Test mean loss is: 14.132447816471794\n",
      "Add tree number 7\n",
      "Train mean loss is: 14.74000834190575\n",
      "Test mean loss is: 14.122087220551563\n",
      "Add tree number 8\n",
      "Train mean loss is: 14.67290457468595\n",
      "Test mean loss is: 14.121597220631301\n",
      "Add tree number 9\n",
      "Train mean loss is: 14.623013663232756\n",
      "Test mean loss is: 14.076753625396405\n",
      "Add tree number 10\n",
      "Train mean loss is: 14.57011154320991\n",
      "Test mean loss is: 14.056770090618375\n",
      "Add tree number 11\n",
      "Train mean loss is: 14.532228227370169\n",
      "Test mean loss is: 14.057923663280672\n",
      "Add tree number 12\n",
      "Train mean loss is: 14.451387603354174\n",
      "Test mean loss is: 14.039205025228302\n",
      "Add tree number 13\n",
      "Train mean loss is: 14.42034884869362\n",
      "Test mean loss is: 14.033525418011225\n",
      "Add tree number 14\n",
      "Train mean loss is: 14.385766466736948\n",
      "Test mean loss is: 14.006742957390752\n",
      "Add tree number 15\n",
      "Train mean loss is: 14.362552661513606\n",
      "Test mean loss is: 13.998313987487844\n",
      "Add tree number 16\n",
      "Train mean loss is: 14.33580683641751\n",
      "Test mean loss is: 14.00087061342044\n",
      "Add tree number 17\n",
      "Train mean loss is: 14.317989636906468\n",
      "Test mean loss is: 13.990210099807552\n",
      "Add tree number 18\n",
      "Train mean loss is: 14.297436424233885\n",
      "Test mean loss is: 13.99188743615073\n",
      "Add tree number 19\n",
      "Train mean loss is: 14.271334883119232\n",
      "Test mean loss is: 13.980248743359807\n",
      "Add tree number 20\n",
      "Train mean loss is: 14.253664927206659\n",
      "Test mean loss is: 13.98048484349419\n",
      "Add tree number 21\n",
      "Train mean loss is: 14.244325791634415\n",
      "Test mean loss is: 13.983289094958643\n",
      "Add tree number 22\n",
      "Train mean loss is: 14.228081445095455\n",
      "Test mean loss is: 13.975474663438318\n",
      "Add tree number 23\n",
      "Train mean loss is: 14.218817214401955\n",
      "Test mean loss is: 13.974387024150012\n",
      "Add tree number 24\n",
      "Train mean loss is: 14.212764845028424\n",
      "Test mean loss is: 13.977592024699991\n",
      "Add tree number 25\n",
      "Train mean loss is: 14.191767836132886\n",
      "Test mean loss is: 13.967352073008637\n",
      "Add tree number 26\n",
      "Train mean loss is: 14.160417205960949\n",
      "Test mean loss is: 13.941598673265787\n",
      "Add tree number 27\n",
      "Train mean loss is: 14.1470248869132\n",
      "Test mean loss is: 13.93760622025914\n",
      "Add tree number 28\n",
      "Train mean loss is: 14.136896947445665\n",
      "Test mean loss is: 13.938657579813146\n",
      "Add tree number 29\n",
      "Train mean loss is: 14.12432913528339\n",
      "Test mean loss is: 13.942064117044408\n",
      "Add tree number 30\n",
      "Train mean loss is: 14.118663412745917\n",
      "Test mean loss is: 13.94569055686859\n",
      "Add tree number 31\n",
      "Train mean loss is: 14.109543668941082\n",
      "Test mean loss is: 13.928368346622458\n",
      "Add tree number 32\n",
      "Train mean loss is: 14.095900539857684\n",
      "Test mean loss is: 13.940834124452348\n",
      "Add tree number 33\n",
      "Train mean loss is: 14.08033454030366\n",
      "Test mean loss is: 13.939520965317614\n",
      "Add tree number 34\n",
      "Train mean loss is: 14.073066532679713\n",
      "Test mean loss is: 13.943198199941726\n",
      "Add tree number 35\n",
      "Train mean loss is: 14.06079345837623\n",
      "Test mean loss is: 13.935209935873848\n",
      "Add tree number 36\n",
      "Train mean loss is: 14.054124446830546\n",
      "Test mean loss is: 13.919402948193607\n",
      "Add tree number 37\n",
      "Train mean loss is: 14.044366801306523\n",
      "Test mean loss is: 13.918111081757433\n",
      "Add tree number 38\n",
      "Train mean loss is: 14.026942138151352\n",
      "Test mean loss is: 13.914314231167321\n",
      "Add tree number 39\n",
      "Train mean loss is: 14.0208166550491\n",
      "Test mean loss is: 13.9153427468782\n",
      "Add tree number 40\n",
      "Train mean loss is: 14.015059542278024\n",
      "Test mean loss is: 13.912182690988692\n",
      "Add tree number 41\n",
      "Train mean loss is: 14.003522767363192\n",
      "Test mean loss is: 13.921230682867593\n",
      "Add tree number 42\n",
      "Train mean loss is: 13.995896815871477\n",
      "Test mean loss is: 13.92017399701868\n",
      "Add tree number 43\n",
      "Train mean loss is: 13.974512801583968\n",
      "Test mean loss is: 13.895801123714838\n",
      "Add tree number 44\n",
      "Train mean loss is: 13.969326299520715\n",
      "Test mean loss is: 13.897544150373706\n",
      "Add tree number 45\n",
      "Train mean loss is: 13.962941131096601\n",
      "Test mean loss is: 13.905116035956496\n",
      "Add tree number 46\n",
      "Train mean loss is: 13.956668469611275\n",
      "Test mean loss is: 13.90129012926787\n",
      "Add tree number 47\n",
      "Train mean loss is: 13.944948712465516\n",
      "Test mean loss is: 13.892876854813437\n",
      "Add tree number 48\n",
      "Train mean loss is: 13.932036434196046\n",
      "Test mean loss is: 13.902884845411366\n",
      "Add tree number 49\n",
      "Train mean loss is: 13.916192751978022\n",
      "Test mean loss is: 13.88046695625568\n",
      "Add tree number 50\n",
      "Train mean loss is: 13.905103372109535\n",
      "Test mean loss is: 13.880158578006354\n",
      "Add tree number 51\n",
      "Train mean loss is: 13.89241003252053\n",
      "Test mean loss is: 13.872251720564881\n",
      "Add tree number 52\n",
      "Train mean loss is: 13.885456707149237\n",
      "Test mean loss is: 13.88213206215379\n",
      "Add tree number 53\n",
      "Train mean loss is: 13.877572672530464\n",
      "Test mean loss is: 13.881158606298493\n",
      "Add tree number 54\n",
      "Train mean loss is: 13.873448568927385\n",
      "Test mean loss is: 13.881693418095418\n",
      "Add tree number 55\n",
      "Train mean loss is: 13.866792592296543\n",
      "Test mean loss is: 13.884999581776256\n",
      "Add tree number 56\n",
      "Train mean loss is: 13.855362171877452\n",
      "Test mean loss is: 13.874069890519646\n",
      "Add tree number 57\n",
      "Train mean loss is: 13.84193667785322\n",
      "Test mean loss is: 13.896044710054976\n",
      "Add tree number 58\n",
      "Train mean loss is: 13.834802503548671\n",
      "Test mean loss is: 13.88843165968056\n",
      "Add tree number 59\n",
      "Train mean loss is: 13.82168370753367\n",
      "Test mean loss is: 13.895453576294985\n",
      "Add tree number 60\n",
      "Train mean loss is: 13.808821915315248\n",
      "Test mean loss is: 13.886572521772473\n",
      "Add tree number 61\n",
      "Train mean loss is: 13.801657412888579\n",
      "Test mean loss is: 13.891041983035564\n",
      "Add tree number 62\n",
      "Train mean loss is: 13.797540047215149\n",
      "Test mean loss is: 13.894357881400104\n",
      "Add tree number 63\n",
      "Train mean loss is: 13.79051273504024\n",
      "Test mean loss is: 13.900866116924407\n",
      "Add tree number 64\n",
      "Train mean loss is: 13.78031323860489\n",
      "Test mean loss is: 13.913277112258008\n",
      "Add tree number 65\n",
      "Train mean loss is: 13.773319585437031\n",
      "Test mean loss is: 13.917986201617433\n",
      "Add tree number 66\n",
      "Train mean loss is: 13.767741916897998\n",
      "Test mean loss is: 13.912361149855712\n",
      "Add tree number 67\n",
      "Train mean loss is: 13.761936098190484\n",
      "Test mean loss is: 13.913502042861927\n",
      "Add tree number 68\n",
      "Train mean loss is: 13.749170212329005\n",
      "Test mean loss is: 13.910720549306903\n",
      "Add tree number 69\n",
      "Train mean loss is: 13.73822231054788\n",
      "Test mean loss is: 13.90657206589913\n",
      "Add tree number 70\n",
      "Train mean loss is: 13.730807393468744\n",
      "Test mean loss is: 13.908569572901527\n",
      "Add tree number 71\n",
      "Train mean loss is: 13.721778058467171\n",
      "Test mean loss is: 13.91784151885341\n",
      "Add tree number 72\n",
      "Train mean loss is: 13.71683893514657\n",
      "Test mean loss is: 13.919152131241258\n",
      "Add tree number 73\n",
      "Train mean loss is: 13.707296618585616\n",
      "Test mean loss is: 13.914671295986587\n",
      "Add tree number 74\n",
      "Train mean loss is: 13.700137706938897\n",
      "Test mean loss is: 13.914572895926465\n",
      "Add tree number 75\n",
      "Train mean loss is: 13.69361281928698\n",
      "Test mean loss is: 13.910156233097178\n",
      "Add tree number 76\n",
      "Train mean loss is: 13.691047048803705\n",
      "Test mean loss is: 13.905785608761354\n",
      "Add tree number 77\n",
      "Train mean loss is: 13.685563139866684\n",
      "Test mean loss is: 13.919424564456884\n",
      "Add tree number 78\n",
      "Train mean loss is: 13.681761053828998\n",
      "Test mean loss is: 13.92365833060623\n",
      "Add tree number 79\n",
      "Train mean loss is: 13.668991774780109\n",
      "Test mean loss is: 13.92200262109825\n",
      "Add tree number 80\n",
      "Train mean loss is: 13.661934160046426\n",
      "Test mean loss is: 13.923440019064355\n",
      "Add tree number 81\n",
      "Train mean loss is: 13.658836169125598\n",
      "Test mean loss is: 13.92105182086027\n",
      "Add tree number 82\n",
      "Train mean loss is: 13.651448668251563\n",
      "Test mean loss is: 13.92630514856649\n",
      "Add tree number 83\n",
      "Train mean loss is: 13.645774376212351\n",
      "Test mean loss is: 13.925144639876862\n",
      "Add tree number 84\n",
      "Train mean loss is: 13.64424722115187\n",
      "Test mean loss is: 13.922791140370348\n",
      "Add tree number 85\n",
      "Train mean loss is: 13.639472585945327\n",
      "Test mean loss is: 13.93026014648271\n",
      "Add tree number 86\n",
      "Train mean loss is: 13.628228535111884\n",
      "Test mean loss is: 13.93693974316335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 87\n",
      "Train mean loss is: 13.62102336240694\n",
      "Test mean loss is: 13.938558494284718\n",
      "Add tree number 88\n",
      "Train mean loss is: 13.612790852645013\n",
      "Test mean loss is: 13.938062749792694\n",
      "Add tree number 89\n",
      "Train mean loss is: 13.605249410085575\n",
      "Test mean loss is: 13.935672065249149\n",
      "Add tree number 90\n",
      "Train mean loss is: 13.600777810560668\n",
      "Test mean loss is: 13.93727867883587\n",
      "Add tree number 91\n",
      "Train mean loss is: 13.594099945542974\n",
      "Test mean loss is: 13.939749592445882\n",
      "Add tree number 92\n",
      "Train mean loss is: 13.584687583723511\n",
      "Test mean loss is: 13.937987046839405\n",
      "Add tree number 93\n",
      "Train mean loss is: 13.579869699253837\n",
      "Test mean loss is: 13.937151536358682\n",
      "Add tree number 94\n",
      "Train mean loss is: 13.574406283086237\n",
      "Test mean loss is: 13.938508582123651\n",
      "Add tree number 95\n",
      "Train mean loss is: 13.568467831594011\n",
      "Test mean loss is: 13.956459367821937\n",
      "Add tree number 96\n",
      "Train mean loss is: 13.564807967706697\n",
      "Test mean loss is: 13.964983620997428\n",
      "Add tree number 97\n",
      "Train mean loss is: 13.55705917435899\n",
      "Test mean loss is: 13.981443710744083\n",
      "Add tree number 98\n",
      "Train mean loss is: 13.550799643525803\n",
      "Test mean loss is: 13.97691933912858\n",
      "Add tree number 99\n",
      "Train mean loss is: 13.543541579681422\n",
      "Test mean loss is: 13.977578160619268\n",
      "Add tree number 100\n",
      "Train mean loss is: 13.536472336720383\n",
      "Test mean loss is: 13.987687025108727\n",
      "Add tree number 101\n",
      "Train mean loss is: 13.53138400583263\n",
      "Test mean loss is: 13.991179137742797\n",
      "Add tree number 102\n",
      "Train mean loss is: 13.528720814300769\n",
      "Test mean loss is: 13.983709426155846\n",
      "Add tree number 103\n",
      "Train mean loss is: 13.524091446438094\n",
      "Test mean loss is: 13.974943920488611\n",
      "Add tree number 104\n",
      "Train mean loss is: 13.516553920000291\n",
      "Test mean loss is: 13.982597616729606\n",
      "Add tree number 105\n",
      "Train mean loss is: 13.513091419022075\n",
      "Test mean loss is: 13.98399144395704\n",
      "Add tree number 106\n",
      "Train mean loss is: 13.50575236211735\n",
      "Test mean loss is: 13.986082307716753\n",
      "Add tree number 107\n",
      "Train mean loss is: 13.499284582340525\n",
      "Test mean loss is: 13.985355328338791\n",
      "Add tree number 108\n",
      "Train mean loss is: 13.494889668362644\n",
      "Test mean loss is: 13.986195636196909\n",
      "Add tree number 109\n",
      "Train mean loss is: 13.488140178864109\n",
      "Test mean loss is: 13.986560170182978\n",
      "Add tree number 110\n",
      "Train mean loss is: 13.48299489014818\n",
      "Test mean loss is: 13.990802228808903\n",
      "Add tree number 111\n",
      "Train mean loss is: 13.478993107614297\n",
      "Test mean loss is: 13.990915679715904\n",
      "Add tree number 112\n",
      "Train mean loss is: 13.474594339179829\n",
      "Test mean loss is: 13.991574529254125\n",
      "Add tree number 113\n",
      "Train mean loss is: 13.470122027346466\n",
      "Test mean loss is: 13.990716711276207\n",
      "Add tree number 114\n",
      "Train mean loss is: 13.465149032017477\n",
      "Test mean loss is: 13.997524013483366\n",
      "Add tree number 115\n",
      "Train mean loss is: 13.458006402058349\n",
      "Test mean loss is: 13.994621681158916\n",
      "Add tree number 116\n",
      "Train mean loss is: 13.454007284555932\n",
      "Test mean loss is: 13.996762566398937\n",
      "Add tree number 117\n",
      "Train mean loss is: 13.449279552684132\n",
      "Test mean loss is: 14.002396488117702\n",
      "Add tree number 118\n",
      "Train mean loss is: 13.444130594618043\n",
      "Test mean loss is: 14.000809700289272\n",
      "Add tree number 119\n",
      "Train mean loss is: 13.437896828009771\n",
      "Test mean loss is: 13.999534986815975\n",
      "Add tree number 120\n",
      "Train mean loss is: 13.435233847034077\n",
      "Test mean loss is: 13.987445829112511\n",
      "Add tree number 121\n",
      "Train mean loss is: 13.431811583749875\n",
      "Test mean loss is: 13.988529749371295\n",
      "Add tree number 122\n",
      "Train mean loss is: 13.429116897165825\n",
      "Test mean loss is: 13.983715107651939\n",
      "Add tree number 123\n",
      "Train mean loss is: 13.425094880725336\n",
      "Test mean loss is: 13.994426282665435\n",
      "Add tree number 124\n",
      "Train mean loss is: 13.423106989000114\n",
      "Test mean loss is: 13.995256512750965\n",
      "Add tree number 125\n",
      "Train mean loss is: 13.415137023079444\n",
      "Test mean loss is: 13.980976724647709\n",
      "Add tree number 126\n",
      "Train mean loss is: 13.409200186309237\n",
      "Test mean loss is: 13.983282440019767\n",
      "Add tree number 127\n",
      "Train mean loss is: 13.40508114075699\n",
      "Test mean loss is: 13.988051686849845\n",
      "Add tree number 128\n",
      "Train mean loss is: 13.401195132068422\n",
      "Test mean loss is: 13.98945183311764\n",
      "Add tree number 129\n",
      "Train mean loss is: 13.395786244318266\n",
      "Test mean loss is: 13.991620768441107\n",
      "Add tree number 130\n",
      "Train mean loss is: 13.393104527737414\n",
      "Test mean loss is: 13.988545703013706\n",
      "Add tree number 131\n",
      "Train mean loss is: 13.388148851999048\n",
      "Test mean loss is: 13.987177598745689\n",
      "Add tree number 132\n",
      "Train mean loss is: 13.380419997568543\n",
      "Test mean loss is: 13.984532230278276\n",
      "Add tree number 133\n",
      "Train mean loss is: 13.377340609652698\n",
      "Test mean loss is: 13.99081300421974\n",
      "Add tree number 134\n",
      "Train mean loss is: 13.372875619381317\n",
      "Test mean loss is: 13.990391709302422\n",
      "Add tree number 135\n",
      "Train mean loss is: 13.366833433413852\n",
      "Test mean loss is: 13.994272321489353\n",
      "Add tree number 136\n",
      "Train mean loss is: 13.363410159286493\n",
      "Test mean loss is: 13.994042945917634\n",
      "Add tree number 137\n",
      "Train mean loss is: 13.360609707127352\n",
      "Test mean loss is: 13.994245971371937\n",
      "Add tree number 138\n",
      "Train mean loss is: 13.356306990072554\n",
      "Test mean loss is: 13.991779282239674\n",
      "Add tree number 139\n",
      "Train mean loss is: 13.350433166270674\n",
      "Test mean loss is: 13.998126016885614\n",
      "Add tree number 140\n",
      "Train mean loss is: 13.346587426752608\n",
      "Test mean loss is: 13.992433901653444\n",
      "Add tree number 141\n",
      "Train mean loss is: 13.342016343434084\n",
      "Test mean loss is: 13.99463874446996\n",
      "Add tree number 142\n",
      "Train mean loss is: 13.336870600043884\n",
      "Test mean loss is: 13.995639020233588\n",
      "Add tree number 143\n",
      "Train mean loss is: 13.33559480168706\n",
      "Test mean loss is: 13.998819880484179\n",
      "Add tree number 144\n",
      "Train mean loss is: 13.331029154020692\n",
      "Test mean loss is: 14.000972447971176\n",
      "Add tree number 145\n",
      "Train mean loss is: 13.325681644511548\n",
      "Test mean loss is: 14.009848914245918\n",
      "Add tree number 146\n",
      "Train mean loss is: 13.322625607426465\n",
      "Test mean loss is: 14.004994321427377\n",
      "Add tree number 147\n",
      "Train mean loss is: 13.317381445542717\n",
      "Test mean loss is: 14.002128349309935\n",
      "Add tree number 148\n",
      "Train mean loss is: 13.315207278513753\n",
      "Test mean loss is: 14.005256122936194\n",
      "Add tree number 149\n",
      "Train mean loss is: 13.308761040615439\n",
      "Test mean loss is: 13.99609965293089\n",
      "Add tree number 150\n",
      "Train mean loss is: 13.3062966672064\n",
      "Test mean loss is: 13.986603007687817\n",
      "Add tree number 151\n",
      "Train mean loss is: 13.300296179311522\n",
      "Test mean loss is: 13.989137541267365\n",
      "Add tree number 152\n",
      "Train mean loss is: 13.297066229492707\n",
      "Test mean loss is: 13.991394912609026\n",
      "Add tree number 153\n",
      "Train mean loss is: 13.292745920183975\n",
      "Test mean loss is: 13.986358228986226\n",
      "Add tree number 154\n",
      "Train mean loss is: 13.290092986752445\n",
      "Test mean loss is: 13.9817636651678\n",
      "Add tree number 155\n",
      "Train mean loss is: 13.288424403742122\n",
      "Test mean loss is: 13.981122686757148\n",
      "Add tree number 156\n",
      "Train mean loss is: 13.28486126688648\n",
      "Test mean loss is: 13.984323154653671\n",
      "Add tree number 157\n",
      "Train mean loss is: 13.281618686134136\n",
      "Test mean loss is: 13.990913898484495\n",
      "Add tree number 158\n",
      "Train mean loss is: 13.277385865820566\n",
      "Test mean loss is: 13.989428268123095\n",
      "Add tree number 159\n",
      "Train mean loss is: 13.270921477984938\n",
      "Test mean loss is: 13.989999609999058\n",
      "Add tree number 160\n",
      "Train mean loss is: 13.26584414483202\n",
      "Test mean loss is: 13.997685451712456\n",
      "Add tree number 161\n",
      "Train mean loss is: 13.261734471980718\n",
      "Test mean loss is: 13.996228163416122\n",
      "Add tree number 162\n",
      "Train mean loss is: 13.256624471693634\n",
      "Test mean loss is: 14.001524870693201\n",
      "Add tree number 163\n",
      "Train mean loss is: 13.253058210531723\n",
      "Test mean loss is: 13.999364746185908\n",
      "Add tree number 164\n",
      "Train mean loss is: 13.248704078326744\n",
      "Test mean loss is: 14.00470216730906\n",
      "Add tree number 165\n",
      "Train mean loss is: 13.247711490029868\n",
      "Test mean loss is: 14.004728931578983\n",
      "Add tree number 166\n",
      "Train mean loss is: 13.243058215847151\n",
      "Test mean loss is: 14.001070934305924\n",
      "Add tree number 167\n",
      "Train mean loss is: 13.23944681068775\n",
      "Test mean loss is: 14.001079149290993\n",
      "Add tree number 168\n",
      "Train mean loss is: 13.236342459914061\n",
      "Test mean loss is: 14.002763026292126\n",
      "Add tree number 169\n",
      "Train mean loss is: 13.230839526673872\n",
      "Test mean loss is: 14.005895440014374\n",
      "Add tree number 170\n",
      "Train mean loss is: 13.225913742606846\n",
      "Test mean loss is: 14.010467123841677\n",
      "Add tree number 171\n",
      "Train mean loss is: 13.223976968019755\n",
      "Test mean loss is: 14.01470879740853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 172\n",
      "Train mean loss is: 13.219899094488003\n",
      "Test mean loss is: 14.019122117470069\n",
      "Add tree number 173\n",
      "Train mean loss is: 13.215628028657328\n",
      "Test mean loss is: 14.018194284938538\n",
      "Add tree number 174\n",
      "Train mean loss is: 13.211941949068414\n",
      "Test mean loss is: 14.016270715675828\n",
      "Add tree number 175\n",
      "Train mean loss is: 13.209145723705353\n",
      "Test mean loss is: 14.024570619376826\n",
      "Add tree number 176\n",
      "Train mean loss is: 13.204506860807012\n",
      "Test mean loss is: 14.022958584962605\n",
      "Add tree number 177\n",
      "Train mean loss is: 13.199852698303207\n",
      "Test mean loss is: 14.023746365503396\n",
      "Add tree number 178\n",
      "Train mean loss is: 13.195204734990105\n",
      "Test mean loss is: 14.025784156538345\n",
      "Add tree number 179\n",
      "Train mean loss is: 13.18935644242755\n",
      "Test mean loss is: 14.014087983903305\n",
      "Add tree number 180\n",
      "Train mean loss is: 13.181779558428666\n",
      "Test mean loss is: 14.013964628381611\n",
      "Add tree number 181\n",
      "Train mean loss is: 13.17920885776828\n",
      "Test mean loss is: 14.014421159385154\n",
      "Add tree number 182\n",
      "Train mean loss is: 13.17485920709456\n",
      "Test mean loss is: 14.009363033646617\n",
      "Add tree number 183\n",
      "Train mean loss is: 13.169675812854903\n",
      "Test mean loss is: 14.009241881840639\n",
      "Add tree number 184\n",
      "Train mean loss is: 13.16725674540578\n",
      "Test mean loss is: 14.007365917452672\n",
      "Add tree number 185\n",
      "Train mean loss is: 13.160857608031087\n",
      "Test mean loss is: 14.006722887066575\n",
      "Add tree number 186\n",
      "Train mean loss is: 13.154745255765206\n",
      "Test mean loss is: 14.00751626768641\n",
      "Add tree number 187\n",
      "Train mean loss is: 13.150687339277816\n",
      "Test mean loss is: 14.012223246428874\n",
      "Add tree number 188\n",
      "Train mean loss is: 13.148173628708943\n",
      "Test mean loss is: 14.01695657730108\n",
      "Add tree number 189\n",
      "Train mean loss is: 13.144045450591154\n",
      "Test mean loss is: 14.020131465217293\n",
      "Add tree number 190\n",
      "Train mean loss is: 13.14073199811164\n",
      "Test mean loss is: 14.023217395463375\n",
      "Add tree number 191\n",
      "Train mean loss is: 13.13812762174386\n",
      "Test mean loss is: 14.017016896201723\n",
      "Add tree number 192\n",
      "Train mean loss is: 13.133987960875107\n",
      "Test mean loss is: 14.018301815333016\n",
      "Add tree number 193\n",
      "Train mean loss is: 13.131328698206058\n",
      "Test mean loss is: 14.028397641539492\n",
      "Add tree number 194\n",
      "Train mean loss is: 13.127024780758386\n",
      "Test mean loss is: 14.029618419533616\n",
      "Add tree number 195\n",
      "Train mean loss is: 13.117655244486514\n",
      "Test mean loss is: 14.033471635380343\n",
      "Add tree number 196\n",
      "Train mean loss is: 13.113187940019376\n",
      "Test mean loss is: 14.021203651157956\n",
      "Add tree number 197\n",
      "Train mean loss is: 13.10913723002689\n",
      "Test mean loss is: 14.022680643967279\n",
      "Add tree number 198\n",
      "Train mean loss is: 13.105157704999788\n",
      "Test mean loss is: 14.027389758536534\n",
      "Add tree number 199\n",
      "Train mean loss is: 13.10113927228356\n",
      "Test mean loss is: 14.021522971994678\n",
      "Add tree number 200\n",
      "Train mean loss is: 13.098750521943035\n",
      "Test mean loss is: 14.025585274230044\n",
      "Add tree number 201\n",
      "Train mean loss is: 13.095839708268612\n",
      "Test mean loss is: 14.030128521728004\n",
      "Add tree number 202\n",
      "Train mean loss is: 13.093101479070295\n",
      "Test mean loss is: 14.03428650029969\n",
      "Add tree number 203\n",
      "Train mean loss is: 13.089905142620811\n",
      "Test mean loss is: 14.043521327048657\n",
      "Add tree number 204\n",
      "Train mean loss is: 13.08348898292745\n",
      "Test mean loss is: 14.044354468212\n",
      "Add tree number 205\n",
      "Train mean loss is: 13.081039223511187\n",
      "Test mean loss is: 14.043751638859897\n",
      "Add tree number 206\n",
      "Train mean loss is: 13.075788489227188\n",
      "Test mean loss is: 14.04706501460122\n",
      "Add tree number 207\n",
      "Train mean loss is: 13.07249455883983\n",
      "Test mean loss is: 14.049505055862648\n",
      "Add tree number 208\n",
      "Train mean loss is: 13.071343087326536\n",
      "Test mean loss is: 14.047036770974893\n",
      "Add tree number 209\n",
      "Train mean loss is: 13.068761617250972\n",
      "Test mean loss is: 14.048047129740901\n",
      "Add tree number 210\n",
      "Train mean loss is: 13.065899941247443\n",
      "Test mean loss is: 14.052731503303928\n",
      "Add tree number 211\n",
      "Train mean loss is: 13.062610668841913\n",
      "Test mean loss is: 14.055160375485418\n",
      "Add tree number 212\n",
      "Train mean loss is: 13.06161138202381\n",
      "Test mean loss is: 14.0502012769175\n",
      "Add tree number 213\n",
      "Train mean loss is: 13.057944920296666\n",
      "Test mean loss is: 14.049042285975855\n",
      "Add tree number 214\n",
      "Train mean loss is: 13.055187357955413\n",
      "Test mean loss is: 14.054135516013696\n",
      "Add tree number 215\n",
      "Train mean loss is: 13.051670689738469\n",
      "Test mean loss is: 14.052209191247806\n",
      "Add tree number 216\n",
      "Train mean loss is: 13.049326255630396\n",
      "Test mean loss is: 14.055291688496926\n",
      "Add tree number 217\n",
      "Train mean loss is: 13.047431562328889\n",
      "Test mean loss is: 14.053268186725155\n",
      "Add tree number 218\n",
      "Train mean loss is: 13.045518374711927\n",
      "Test mean loss is: 14.05517195234445\n",
      "Add tree number 219\n",
      "Train mean loss is: 13.041635225207804\n",
      "Test mean loss is: 14.055001234953933\n",
      "Add tree number 220\n",
      "Train mean loss is: 13.03769835858107\n",
      "Test mean loss is: 14.063387558715947\n",
      "Add tree number 221\n",
      "Train mean loss is: 13.03357268735584\n",
      "Test mean loss is: 14.059980326212969\n",
      "Add tree number 222\n",
      "Train mean loss is: 13.029075290086954\n",
      "Test mean loss is: 14.062114325387672\n",
      "Add tree number 223\n",
      "Train mean loss is: 13.024634801840609\n",
      "Test mean loss is: 14.058015800890688\n",
      "Add tree number 224\n",
      "Train mean loss is: 13.02279508858583\n",
      "Test mean loss is: 14.061360702474214\n",
      "Add tree number 225\n",
      "Train mean loss is: 13.018224753523128\n",
      "Test mean loss is: 14.066293536879188\n",
      "Add tree number 226\n",
      "Train mean loss is: 13.01409959627131\n",
      "Test mean loss is: 14.071658734318893\n",
      "Add tree number 227\n",
      "Train mean loss is: 13.011243866126248\n",
      "Test mean loss is: 14.076179404907126\n",
      "Add tree number 228\n",
      "Train mean loss is: 13.008531320310443\n",
      "Test mean loss is: 14.073422619249397\n",
      "Add tree number 229\n",
      "Train mean loss is: 13.004673264459925\n",
      "Test mean loss is: 14.077236278389599\n",
      "Add tree number 230\n",
      "Train mean loss is: 13.000293211146099\n",
      "Test mean loss is: 14.078907437170727\n",
      "Add tree number 231\n",
      "Train mean loss is: 12.997731594938243\n",
      "Test mean loss is: 14.083244560997267\n",
      "Add tree number 232\n",
      "Train mean loss is: 12.993201720677634\n",
      "Test mean loss is: 14.081605026777398\n",
      "Add tree number 233\n",
      "Train mean loss is: 12.987024591902943\n",
      "Test mean loss is: 14.086452380256198\n",
      "Add tree number 234\n",
      "Train mean loss is: 12.983657481130033\n",
      "Test mean loss is: 14.089730124987554\n",
      "Add tree number 235\n",
      "Train mean loss is: 12.978650112431309\n",
      "Test mean loss is: 14.091803174973672\n",
      "Add tree number 236\n",
      "Train mean loss is: 12.977665342368184\n",
      "Test mean loss is: 14.094067698323691\n",
      "Add tree number 237\n",
      "Train mean loss is: 12.974291210133021\n",
      "Test mean loss is: 14.094240131212707\n",
      "Add tree number 238\n",
      "Train mean loss is: 12.970510340830389\n",
      "Test mean loss is: 14.095769502161343\n",
      "Add tree number 239\n",
      "Train mean loss is: 12.968776890554308\n",
      "Test mean loss is: 14.096265134254118\n",
      "Add tree number 240\n",
      "Train mean loss is: 12.961693149384553\n",
      "Test mean loss is: 14.079380571889478\n",
      "Add tree number 241\n",
      "Train mean loss is: 12.957511248781614\n",
      "Test mean loss is: 14.074935079123831\n",
      "Add tree number 242\n",
      "Train mean loss is: 12.956673264156194\n",
      "Test mean loss is: 14.075255634138765\n",
      "Add tree number 243\n",
      "Train mean loss is: 12.955227471904678\n",
      "Test mean loss is: 14.07135105514797\n",
      "Add tree number 244\n",
      "Train mean loss is: 12.952949559041695\n",
      "Test mean loss is: 14.072019278152542\n",
      "Add tree number 245\n",
      "Train mean loss is: 12.94716735188305\n",
      "Test mean loss is: 14.072562956738919\n",
      "Add tree number 246\n",
      "Train mean loss is: 12.94192125875945\n",
      "Test mean loss is: 14.077678981104032\n",
      "Add tree number 247\n",
      "Train mean loss is: 12.939065456918877\n",
      "Test mean loss is: 14.07701617463752\n",
      "Add tree number 248\n",
      "Train mean loss is: 12.936934545775978\n",
      "Test mean loss is: 14.07953661297751\n",
      "Add tree number 249\n",
      "Train mean loss is: 12.931003546865584\n",
      "Test mean loss is: 14.078661448483206\n",
      "Add tree number 250\n",
      "Train mean loss is: 12.927249552457898\n",
      "Test mean loss is: 14.08201396792154\n",
      "Add tree number 251\n",
      "Train mean loss is: 12.92379552689775\n",
      "Test mean loss is: 14.08624392130209\n",
      "Add tree number 252\n",
      "Train mean loss is: 12.920581954977775\n",
      "Test mean loss is: 14.086964898711443\n",
      "Add tree number 253\n",
      "Train mean loss is: 12.917068222136058\n",
      "Test mean loss is: 14.088126710582525\n",
      "Add tree number 254\n",
      "Train mean loss is: 12.914900591373595\n",
      "Test mean loss is: 14.090781868547849\n",
      "Add tree number 255\n",
      "Train mean loss is: 12.912601389413187\n",
      "Test mean loss is: 14.090285760358343\n",
      "Add tree number 256\n",
      "Train mean loss is: 12.906674193624715\n",
      "Test mean loss is: 14.089639132540004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 257\n",
      "Train mean loss is: 12.904022731409334\n",
      "Test mean loss is: 14.091642651075729\n",
      "Add tree number 258\n",
      "Train mean loss is: 12.900066655363977\n",
      "Test mean loss is: 14.092429314616522\n",
      "Add tree number 259\n",
      "Train mean loss is: 12.897233001208951\n",
      "Test mean loss is: 14.095182808521432\n",
      "Add tree number 260\n",
      "Train mean loss is: 12.894773221632608\n",
      "Test mean loss is: 14.094280782044077\n",
      "Add tree number 261\n",
      "Train mean loss is: 12.891762949862995\n",
      "Test mean loss is: 14.08975180979072\n",
      "Add tree number 262\n",
      "Train mean loss is: 12.888975191350484\n",
      "Test mean loss is: 14.087517592823072\n",
      "Add tree number 263\n",
      "Train mean loss is: 12.88676865034709\n",
      "Test mean loss is: 14.086932387511872\n",
      "Add tree number 264\n",
      "Train mean loss is: 12.88391678354482\n",
      "Test mean loss is: 14.087936809494966\n",
      "Add tree number 265\n",
      "Train mean loss is: 12.877745836031384\n",
      "Test mean loss is: 14.09629198633844\n",
      "Add tree number 266\n",
      "Train mean loss is: 12.875088919249086\n",
      "Test mean loss is: 14.095965966082957\n",
      "Add tree number 267\n",
      "Train mean loss is: 12.872691992714106\n",
      "Test mean loss is: 14.096489699283323\n",
      "Add tree number 268\n",
      "Train mean loss is: 12.868394726184594\n",
      "Test mean loss is: 14.095836912006181\n",
      "Add tree number 269\n",
      "Train mean loss is: 12.865894037595128\n",
      "Test mean loss is: 14.096123376626261\n",
      "Add tree number 270\n",
      "Train mean loss is: 12.863763021063976\n",
      "Test mean loss is: 14.08962495555403\n",
      "Add tree number 271\n",
      "Train mean loss is: 12.86229963040031\n",
      "Test mean loss is: 14.092284801419943\n",
      "Add tree number 272\n",
      "Train mean loss is: 12.858735084066316\n",
      "Test mean loss is: 14.104983287049574\n",
      "Add tree number 273\n",
      "Train mean loss is: 12.85446049506553\n",
      "Test mean loss is: 14.107045482083251\n",
      "Add tree number 274\n",
      "Train mean loss is: 12.851212602142649\n",
      "Test mean loss is: 14.103779361810917\n",
      "Add tree number 275\n",
      "Train mean loss is: 12.849226160203676\n",
      "Test mean loss is: 14.108928355702748\n",
      "Add tree number 276\n",
      "Train mean loss is: 12.845541554104875\n",
      "Test mean loss is: 14.111438642664398\n",
      "Add tree number 277\n",
      "Train mean loss is: 12.842786112345028\n",
      "Test mean loss is: 14.110606415024137\n",
      "Add tree number 278\n",
      "Train mean loss is: 12.839340026013705\n",
      "Test mean loss is: 14.112826546695002\n",
      "Add tree number 279\n",
      "Train mean loss is: 12.835584085871027\n",
      "Test mean loss is: 14.104018228033954\n",
      "Add tree number 280\n",
      "Train mean loss is: 12.83112069941326\n",
      "Test mean loss is: 14.106034667720607\n",
      "Add tree number 281\n",
      "Train mean loss is: 12.826212331161573\n",
      "Test mean loss is: 14.106385882871137\n",
      "Add tree number 282\n",
      "Train mean loss is: 12.823724839598409\n",
      "Test mean loss is: 14.10473727703915\n",
      "Add tree number 283\n",
      "Train mean loss is: 12.821178220411419\n",
      "Test mean loss is: 14.112131236018818\n",
      "Add tree number 284\n",
      "Train mean loss is: 12.818953660965025\n",
      "Test mean loss is: 14.121625742668117\n",
      "Add tree number 285\n",
      "Train mean loss is: 12.814850413949495\n",
      "Test mean loss is: 14.122669352782333\n",
      "Add tree number 286\n",
      "Train mean loss is: 12.813167529631787\n",
      "Test mean loss is: 14.119251589892642\n",
      "Add tree number 287\n",
      "Train mean loss is: 12.810555506329822\n",
      "Test mean loss is: 14.128709067806579\n",
      "Add tree number 288\n",
      "Train mean loss is: 12.808188331356618\n",
      "Test mean loss is: 14.125876512146197\n",
      "Add tree number 289\n",
      "Train mean loss is: 12.805282786343751\n",
      "Test mean loss is: 14.124776010162927\n",
      "Add tree number 290\n",
      "Train mean loss is: 12.802371852782569\n",
      "Test mean loss is: 14.129626664910546\n",
      "Add tree number 291\n",
      "Train mean loss is: 12.800937013904523\n",
      "Test mean loss is: 14.126768118543671\n",
      "Add tree number 292\n",
      "Train mean loss is: 12.7971164312356\n",
      "Test mean loss is: 14.13354982697262\n",
      "Add tree number 293\n",
      "Train mean loss is: 12.795041000033809\n",
      "Test mean loss is: 14.132753552278423\n",
      "Add tree number 294\n",
      "Train mean loss is: 12.792489784923445\n",
      "Test mean loss is: 14.13224839113051\n",
      "Add tree number 295\n",
      "Train mean loss is: 12.788650851901451\n",
      "Test mean loss is: 14.136041098922073\n",
      "Add tree number 296\n",
      "Train mean loss is: 12.785963883774645\n",
      "Test mean loss is: 14.142037708834827\n",
      "Add tree number 297\n",
      "Train mean loss is: 12.782028565651196\n",
      "Test mean loss is: 14.141218354279514\n",
      "Add tree number 298\n",
      "Train mean loss is: 12.779681066736496\n",
      "Test mean loss is: 14.139933845690427\n",
      "Add tree number 299\n",
      "Train mean loss is: 12.776044064424353\n",
      "Test mean loss is: 14.141480605862972\n",
      "Add tree number 300\n",
      "Train mean loss is: 12.772233643026732\n",
      "Test mean loss is: 14.15588695323682\n",
      "Start 3 0.6 30\n",
      "Add tree number 1\n",
      "Train mean loss is: 18.192311649307808\n",
      "Test mean loss is: 17.135983002960607\n",
      "Add tree number 2\n",
      "Train mean loss is: 15.651466282266773\n",
      "Test mean loss is: 14.807862556319725\n",
      "Add tree number 3\n",
      "Train mean loss is: 15.087708147536638\n",
      "Test mean loss is: 14.370422335549007\n",
      "Add tree number 4\n",
      "Train mean loss is: 14.90153533034891\n",
      "Test mean loss is: 14.211604566030566\n",
      "Add tree number 5\n",
      "Train mean loss is: 14.75994631353668\n",
      "Test mean loss is: 14.129923790327693\n",
      "Add tree number 6\n",
      "Train mean loss is: 14.668233141971166\n",
      "Test mean loss is: 14.126877240424353\n",
      "Add tree number 7\n",
      "Train mean loss is: 14.579499205683797\n",
      "Test mean loss is: 14.085184842445985\n",
      "Add tree number 8\n",
      "Train mean loss is: 14.50369969737957\n",
      "Test mean loss is: 14.020203390924822\n",
      "Add tree number 9\n",
      "Train mean loss is: 14.445903261730463\n",
      "Test mean loss is: 13.991304699651772\n",
      "Add tree number 10\n",
      "Train mean loss is: 14.386742837502503\n",
      "Test mean loss is: 13.96433668809847\n",
      "Add tree number 11\n",
      "Train mean loss is: 14.360203450388804\n",
      "Test mean loss is: 13.961493777818964\n",
      "Add tree number 12\n",
      "Train mean loss is: 14.332950010549853\n",
      "Test mean loss is: 13.939535556165755\n",
      "Add tree number 13\n",
      "Train mean loss is: 14.296849016021303\n",
      "Test mean loss is: 13.94828341168422\n",
      "Add tree number 14\n",
      "Train mean loss is: 14.274017787872397\n",
      "Test mean loss is: 13.940777412357317\n",
      "Add tree number 15\n",
      "Train mean loss is: 14.245894258498918\n",
      "Test mean loss is: 13.924102030948516\n",
      "Add tree number 16\n",
      "Train mean loss is: 14.211760544444807\n",
      "Test mean loss is: 13.936175366897457\n",
      "Add tree number 17\n",
      "Train mean loss is: 14.190758437223083\n",
      "Test mean loss is: 13.946831500729308\n",
      "Add tree number 18\n",
      "Train mean loss is: 14.170151498482186\n",
      "Test mean loss is: 13.943082824345089\n",
      "Add tree number 19\n",
      "Train mean loss is: 14.153603101380536\n",
      "Test mean loss is: 13.939087836652151\n",
      "Add tree number 20\n",
      "Train mean loss is: 14.138634913415945\n",
      "Test mean loss is: 13.928607500953094\n",
      "Add tree number 21\n",
      "Train mean loss is: 14.127646401582131\n",
      "Test mean loss is: 13.930317440335267\n",
      "Add tree number 22\n",
      "Train mean loss is: 14.10960694264608\n",
      "Test mean loss is: 13.908987738837462\n",
      "Add tree number 23\n",
      "Train mean loss is: 14.066711109024062\n",
      "Test mean loss is: 13.891007260286264\n",
      "Add tree number 24\n",
      "Train mean loss is: 14.03815833016634\n",
      "Test mean loss is: 13.86273573620295\n",
      "Add tree number 25\n",
      "Train mean loss is: 14.027121533058583\n",
      "Test mean loss is: 13.864003050257992\n",
      "Add tree number 26\n",
      "Train mean loss is: 14.012518107634358\n",
      "Test mean loss is: 13.872090273201543\n",
      "Add tree number 27\n",
      "Train mean loss is: 13.99874514203315\n",
      "Test mean loss is: 13.87376959871509\n",
      "Add tree number 28\n",
      "Train mean loss is: 13.985137360723824\n",
      "Test mean loss is: 13.859499404980737\n",
      "Add tree number 29\n",
      "Train mean loss is: 13.977428405769231\n",
      "Test mean loss is: 13.869675924437216\n",
      "Add tree number 30\n",
      "Train mean loss is: 13.95519313019903\n",
      "Test mean loss is: 13.86849111341867\n",
      "Add tree number 31\n",
      "Train mean loss is: 13.941982809289602\n",
      "Test mean loss is: 13.867810307307316\n",
      "Add tree number 32\n",
      "Train mean loss is: 13.930962862589208\n",
      "Test mean loss is: 13.862272490592344\n",
      "Add tree number 33\n",
      "Train mean loss is: 13.923292186289768\n",
      "Test mean loss is: 13.863904501828083\n",
      "Add tree number 34\n",
      "Train mean loss is: 13.91457611897202\n",
      "Test mean loss is: 13.863919958263061\n",
      "Add tree number 35\n",
      "Train mean loss is: 13.898183900799271\n",
      "Test mean loss is: 13.867710780825634\n",
      "Add tree number 36\n",
      "Train mean loss is: 13.89465204895951\n",
      "Test mean loss is: 13.867131796432913\n",
      "Add tree number 37\n",
      "Train mean loss is: 13.887927999930307\n",
      "Test mean loss is: 13.874833172596446\n",
      "Add tree number 38\n",
      "Train mean loss is: 13.876359501394951\n",
      "Test mean loss is: 13.87686888645772\n",
      "Add tree number 39\n",
      "Train mean loss is: 13.865758924682229\n",
      "Test mean loss is: 13.87598129596091\n",
      "Add tree number 40\n",
      "Train mean loss is: 13.856219874996741\n",
      "Test mean loss is: 13.86704900608977\n",
      "Add tree number 41\n",
      "Train mean loss is: 13.848132807077866\n",
      "Test mean loss is: 13.860439913957213\n",
      "Add tree number 42\n",
      "Train mean loss is: 13.83456618798378\n",
      "Test mean loss is: 13.857993807196591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 43\n",
      "Train mean loss is: 13.823305154632918\n",
      "Test mean loss is: 13.861060170087034\n",
      "Add tree number 44\n",
      "Train mean loss is: 13.809143381752875\n",
      "Test mean loss is: 13.875099792770364\n",
      "Add tree number 45\n",
      "Train mean loss is: 13.800149127393537\n",
      "Test mean loss is: 13.879451972286539\n",
      "Add tree number 46\n",
      "Train mean loss is: 13.787011744964323\n",
      "Test mean loss is: 13.897953805556662\n",
      "Add tree number 47\n",
      "Train mean loss is: 13.770939451529774\n",
      "Test mean loss is: 13.88985884377317\n",
      "Add tree number 48\n",
      "Train mean loss is: 13.760789283091247\n",
      "Test mean loss is: 13.89097460494898\n",
      "Add tree number 49\n",
      "Train mean loss is: 13.755787539291903\n",
      "Test mean loss is: 13.884245046607587\n",
      "Add tree number 50\n",
      "Train mean loss is: 13.745661988424143\n",
      "Test mean loss is: 13.892425784415272\n",
      "Add tree number 51\n",
      "Train mean loss is: 13.736698110013956\n",
      "Test mean loss is: 13.888687383702464\n",
      "Add tree number 52\n",
      "Train mean loss is: 13.720204678115888\n",
      "Test mean loss is: 13.89190229730896\n",
      "Add tree number 53\n",
      "Train mean loss is: 13.716693093157664\n",
      "Test mean loss is: 13.888128474807278\n",
      "Add tree number 54\n",
      "Train mean loss is: 13.71291289610483\n",
      "Test mean loss is: 13.88663150546996\n",
      "Add tree number 55\n",
      "Train mean loss is: 13.706832701350823\n",
      "Test mean loss is: 13.88685365452021\n",
      "Add tree number 56\n",
      "Train mean loss is: 13.69549174082941\n",
      "Test mean loss is: 13.891011060740714\n",
      "Add tree number 57\n",
      "Train mean loss is: 13.686869235806641\n",
      "Test mean loss is: 13.889886846269068\n",
      "Add tree number 58\n",
      "Train mean loss is: 13.68077208593618\n",
      "Test mean loss is: 13.88900245599716\n",
      "Add tree number 59\n",
      "Train mean loss is: 13.674027672309695\n",
      "Test mean loss is: 13.887860692901304\n",
      "Add tree number 60\n",
      "Train mean loss is: 13.663185698057609\n",
      "Test mean loss is: 13.894368978958513\n",
      "Add tree number 61\n",
      "Train mean loss is: 13.651839804702783\n",
      "Test mean loss is: 13.90703011784751\n",
      "Add tree number 62\n",
      "Train mean loss is: 13.64196988723333\n",
      "Test mean loss is: 13.90161490858411\n",
      "Add tree number 63\n",
      "Train mean loss is: 13.623458950945047\n",
      "Test mean loss is: 13.901262203728738\n",
      "Add tree number 64\n",
      "Train mean loss is: 13.609916685224512\n",
      "Test mean loss is: 13.90642136187393\n",
      "Add tree number 65\n",
      "Train mean loss is: 13.598838429485872\n",
      "Test mean loss is: 13.892197912007184\n",
      "Add tree number 66\n",
      "Train mean loss is: 13.588584976575873\n",
      "Test mean loss is: 13.909761365246556\n",
      "Add tree number 67\n",
      "Train mean loss is: 13.582274322186391\n",
      "Test mean loss is: 13.901986062743227\n",
      "Add tree number 68\n",
      "Train mean loss is: 13.575994506115565\n",
      "Test mean loss is: 13.907382800349513\n",
      "Add tree number 69\n",
      "Train mean loss is: 13.572767403822498\n",
      "Test mean loss is: 13.904704282111876\n",
      "Add tree number 70\n",
      "Train mean loss is: 13.561380370622512\n",
      "Test mean loss is: 13.899521618262506\n",
      "Add tree number 71\n",
      "Train mean loss is: 13.556070632151846\n",
      "Test mean loss is: 13.888948958990612\n",
      "Add tree number 72\n",
      "Train mean loss is: 13.545105281481108\n",
      "Test mean loss is: 13.89647773319078\n",
      "Add tree number 73\n",
      "Train mean loss is: 13.53811276093059\n",
      "Test mean loss is: 13.89561623361923\n",
      "Add tree number 74\n",
      "Train mean loss is: 13.532325370625887\n",
      "Test mean loss is: 13.901694248424674\n",
      "Add tree number 75\n",
      "Train mean loss is: 13.526128943592967\n",
      "Test mean loss is: 13.908153297897401\n",
      "Add tree number 76\n",
      "Train mean loss is: 13.518685956810726\n",
      "Test mean loss is: 13.896674958522105\n",
      "Add tree number 77\n",
      "Train mean loss is: 13.508359969555837\n",
      "Test mean loss is: 13.912647547430865\n",
      "Add tree number 78\n",
      "Train mean loss is: 13.50008979406938\n",
      "Test mean loss is: 13.92465916080323\n",
      "Add tree number 79\n",
      "Train mean loss is: 13.494445218928329\n",
      "Test mean loss is: 13.925403289266901\n",
      "Add tree number 80\n",
      "Train mean loss is: 13.489363045932404\n",
      "Test mean loss is: 13.924280660972883\n",
      "Add tree number 81\n",
      "Train mean loss is: 13.478659581533336\n",
      "Test mean loss is: 13.920305436783234\n",
      "Add tree number 82\n",
      "Train mean loss is: 13.462866045271031\n",
      "Test mean loss is: 13.927007329621064\n",
      "Add tree number 83\n",
      "Train mean loss is: 13.451959181841818\n",
      "Test mean loss is: 13.939387742485552\n",
      "Add tree number 84\n",
      "Train mean loss is: 13.446587823370855\n",
      "Test mean loss is: 13.935251244766185\n",
      "Add tree number 85\n",
      "Train mean loss is: 13.438972708470402\n",
      "Test mean loss is: 13.929864300355893\n",
      "Add tree number 86\n",
      "Train mean loss is: 13.41851538385349\n",
      "Test mean loss is: 13.933778040029514\n",
      "Add tree number 87\n",
      "Train mean loss is: 13.412475928864803\n",
      "Test mean loss is: 13.928498952870985\n",
      "Add tree number 88\n",
      "Train mean loss is: 13.406472082482933\n",
      "Test mean loss is: 13.924822779264842\n",
      "Add tree number 89\n",
      "Train mean loss is: 13.40052328372563\n",
      "Test mean loss is: 13.924098230811058\n",
      "Add tree number 90\n",
      "Train mean loss is: 13.394327433151883\n",
      "Test mean loss is: 13.926349392708262\n",
      "Add tree number 91\n",
      "Train mean loss is: 13.387818874325731\n",
      "Test mean loss is: 13.920571915088459\n",
      "Add tree number 92\n",
      "Train mean loss is: 13.377869613375283\n",
      "Test mean loss is: 13.927246376642348\n",
      "Add tree number 93\n",
      "Train mean loss is: 13.371378380306654\n",
      "Test mean loss is: 13.925580199659496\n",
      "Add tree number 94\n",
      "Train mean loss is: 13.365718785515627\n",
      "Test mean loss is: 13.934544681935495\n",
      "Add tree number 95\n",
      "Train mean loss is: 13.358606200602518\n",
      "Test mean loss is: 13.93015482562731\n",
      "Add tree number 96\n",
      "Train mean loss is: 13.354972068398816\n",
      "Test mean loss is: 13.934417214721051\n",
      "Add tree number 97\n",
      "Train mean loss is: 13.348821805418861\n",
      "Test mean loss is: 13.927378004251194\n",
      "Add tree number 98\n",
      "Train mean loss is: 13.341040463963964\n",
      "Test mean loss is: 13.932821069571034\n",
      "Add tree number 99\n",
      "Train mean loss is: 13.327635236405206\n",
      "Test mean loss is: 13.921354908819032\n",
      "Add tree number 100\n",
      "Train mean loss is: 13.323901345117068\n",
      "Test mean loss is: 13.925098804386085\n",
      "Add tree number 101\n",
      "Train mean loss is: 13.320194433845716\n",
      "Test mean loss is: 13.920821808077418\n",
      "Add tree number 102\n",
      "Train mean loss is: 13.310865217883334\n",
      "Test mean loss is: 13.89636674055912\n",
      "Add tree number 103\n",
      "Train mean loss is: 13.305678197542687\n",
      "Test mean loss is: 13.888613657854357\n",
      "Add tree number 104\n",
      "Train mean loss is: 13.29993611992388\n",
      "Test mean loss is: 13.889431645393818\n",
      "Add tree number 105\n",
      "Train mean loss is: 13.291007417908178\n",
      "Test mean loss is: 13.896076020357711\n",
      "Add tree number 106\n",
      "Train mean loss is: 13.280528649150563\n",
      "Test mean loss is: 13.914666435462836\n",
      "Add tree number 107\n",
      "Train mean loss is: 13.275114320926392\n",
      "Test mean loss is: 13.917176165538754\n",
      "Add tree number 108\n",
      "Train mean loss is: 13.269829101187069\n",
      "Test mean loss is: 13.928034461093604\n",
      "Add tree number 109\n",
      "Train mean loss is: 13.26396237556666\n",
      "Test mean loss is: 13.92784603456881\n",
      "Add tree number 110\n",
      "Train mean loss is: 13.258552864903482\n",
      "Test mean loss is: 13.931533532181744\n",
      "Add tree number 111\n",
      "Train mean loss is: 13.256213755924058\n",
      "Test mean loss is: 13.924821846429152\n",
      "Add tree number 112\n",
      "Train mean loss is: 13.251670411197106\n",
      "Test mean loss is: 13.917704699080456\n",
      "Add tree number 113\n",
      "Train mean loss is: 13.243531399711035\n",
      "Test mean loss is: 13.920875721021867\n",
      "Add tree number 114\n",
      "Train mean loss is: 13.235817664748147\n",
      "Test mean loss is: 13.92359397013442\n",
      "Add tree number 115\n",
      "Train mean loss is: 13.231105357457494\n",
      "Test mean loss is: 13.924746957826063\n",
      "Add tree number 116\n",
      "Train mean loss is: 13.224760299428775\n",
      "Test mean loss is: 13.919818580759713\n",
      "Add tree number 117\n",
      "Train mean loss is: 13.221976757608934\n",
      "Test mean loss is: 13.917643214159222\n",
      "Add tree number 118\n",
      "Train mean loss is: 13.213312928005072\n",
      "Test mean loss is: 13.90891561338221\n",
      "Add tree number 119\n",
      "Train mean loss is: 13.209171956215892\n",
      "Test mean loss is: 13.90601615263881\n",
      "Add tree number 120\n",
      "Train mean loss is: 13.202795643122766\n",
      "Test mean loss is: 13.90542200908178\n",
      "Add tree number 121\n",
      "Train mean loss is: 13.198145446857296\n",
      "Test mean loss is: 13.903635712175056\n",
      "Add tree number 122\n",
      "Train mean loss is: 13.193185763611721\n",
      "Test mean loss is: 13.900860992495131\n",
      "Add tree number 123\n",
      "Train mean loss is: 13.190325406401179\n",
      "Test mean loss is: 13.901079907276127\n",
      "Add tree number 124\n",
      "Train mean loss is: 13.184228718251736\n",
      "Test mean loss is: 13.900167284186583\n",
      "Add tree number 125\n",
      "Train mean loss is: 13.18016190517551\n",
      "Test mean loss is: 13.904546012558338\n",
      "Add tree number 126\n",
      "Train mean loss is: 13.17454465787838\n",
      "Test mean loss is: 13.9113723636405\n",
      "Add tree number 127\n",
      "Train mean loss is: 13.168410763872364\n",
      "Test mean loss is: 13.933815965367591\n",
      "Add tree number 128\n",
      "Train mean loss is: 13.159986554023375\n",
      "Test mean loss is: 13.931255544270465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 129\n",
      "Train mean loss is: 13.155128106253647\n",
      "Test mean loss is: 13.930408039323092\n",
      "Add tree number 130\n",
      "Train mean loss is: 13.148035458494075\n",
      "Test mean loss is: 13.937260147392697\n",
      "Add tree number 131\n",
      "Train mean loss is: 13.143044126963986\n",
      "Test mean loss is: 13.939921541016776\n",
      "Add tree number 132\n",
      "Train mean loss is: 13.138155216351194\n",
      "Test mean loss is: 13.94022630650873\n",
      "Add tree number 133\n",
      "Train mean loss is: 13.134523327899519\n",
      "Test mean loss is: 13.934943417869896\n",
      "Add tree number 134\n",
      "Train mean loss is: 13.13099047023953\n",
      "Test mean loss is: 13.938093653905408\n",
      "Add tree number 135\n",
      "Train mean loss is: 13.125535661319054\n",
      "Test mean loss is: 13.931718893616523\n",
      "Add tree number 136\n",
      "Train mean loss is: 13.11949396997046\n",
      "Test mean loss is: 13.933216941979362\n",
      "Add tree number 137\n",
      "Train mean loss is: 13.114303085446213\n",
      "Test mean loss is: 13.938839965932809\n",
      "Add tree number 138\n",
      "Train mean loss is: 13.11214348216107\n",
      "Test mean loss is: 13.937044014432388\n",
      "Add tree number 139\n",
      "Train mean loss is: 13.107251871736619\n",
      "Test mean loss is: 13.93910876592743\n",
      "Add tree number 140\n",
      "Train mean loss is: 13.105779925171223\n",
      "Test mean loss is: 13.940948539609643\n",
      "Add tree number 141\n",
      "Train mean loss is: 13.100814124152066\n",
      "Test mean loss is: 13.946071757824454\n",
      "Add tree number 142\n",
      "Train mean loss is: 13.096356024360857\n",
      "Test mean loss is: 13.957834614945796\n",
      "Add tree number 143\n",
      "Train mean loss is: 13.09502164973722\n",
      "Test mean loss is: 13.959352754932402\n",
      "Add tree number 144\n",
      "Train mean loss is: 13.09273689412008\n",
      "Test mean loss is: 13.961113857542088\n",
      "Add tree number 145\n",
      "Train mean loss is: 13.087633682250805\n",
      "Test mean loss is: 13.961612243174882\n",
      "Add tree number 146\n",
      "Train mean loss is: 13.080914164038294\n",
      "Test mean loss is: 13.963483704090718\n",
      "Add tree number 147\n",
      "Train mean loss is: 13.075373436919364\n",
      "Test mean loss is: 13.970138501645062\n",
      "Add tree number 148\n",
      "Train mean loss is: 13.069565015810626\n",
      "Test mean loss is: 13.975630625036889\n",
      "Add tree number 149\n",
      "Train mean loss is: 13.064896808527115\n",
      "Test mean loss is: 13.975887442800651\n",
      "Add tree number 150\n",
      "Train mean loss is: 13.059078137847896\n",
      "Test mean loss is: 13.978180629434972\n",
      "Add tree number 151\n",
      "Train mean loss is: 13.05411871315952\n",
      "Test mean loss is: 13.983102800421715\n",
      "Add tree number 152\n",
      "Train mean loss is: 13.051134099444164\n",
      "Test mean loss is: 13.985423042474372\n",
      "Add tree number 153\n",
      "Train mean loss is: 13.0458845900314\n",
      "Test mean loss is: 13.985716414582706\n",
      "Add tree number 154\n",
      "Train mean loss is: 13.040784882429543\n",
      "Test mean loss is: 13.989287744381896\n",
      "Add tree number 155\n",
      "Train mean loss is: 13.03599746893503\n",
      "Test mean loss is: 13.98867167175907\n",
      "Add tree number 156\n",
      "Train mean loss is: 13.0318236845651\n",
      "Test mean loss is: 13.981801532978533\n",
      "Add tree number 157\n",
      "Train mean loss is: 13.028528112520137\n",
      "Test mean loss is: 13.98050200790483\n",
      "Add tree number 158\n",
      "Train mean loss is: 13.021457741363847\n",
      "Test mean loss is: 13.98873980836528\n",
      "Add tree number 159\n",
      "Train mean loss is: 13.016912511376207\n",
      "Test mean loss is: 13.985308806172624\n",
      "Add tree number 160\n",
      "Train mean loss is: 13.011958088170337\n",
      "Test mean loss is: 13.966180917976539\n",
      "Add tree number 161\n",
      "Train mean loss is: 13.00568878724813\n",
      "Test mean loss is: 13.9707688243567\n",
      "Add tree number 162\n",
      "Train mean loss is: 13.002786841639548\n",
      "Test mean loss is: 13.971227508042627\n",
      "Add tree number 163\n",
      "Train mean loss is: 12.998521654054025\n",
      "Test mean loss is: 13.96808361716278\n",
      "Add tree number 164\n",
      "Train mean loss is: 12.995355080471528\n",
      "Test mean loss is: 13.96703210165467\n",
      "Add tree number 165\n",
      "Train mean loss is: 12.989407043686567\n",
      "Test mean loss is: 13.957183411257635\n",
      "Add tree number 166\n",
      "Train mean loss is: 12.981815266854818\n",
      "Test mean loss is: 13.950825754623269\n",
      "Add tree number 167\n",
      "Train mean loss is: 12.977811007836822\n",
      "Test mean loss is: 13.957449496759363\n",
      "Add tree number 168\n",
      "Train mean loss is: 12.969923899141474\n",
      "Test mean loss is: 13.964117431277149\n",
      "Add tree number 169\n",
      "Train mean loss is: 12.963279600949106\n",
      "Test mean loss is: 13.966040024901806\n",
      "Add tree number 170\n",
      "Train mean loss is: 12.958590948037406\n",
      "Test mean loss is: 13.979486839818763\n",
      "Add tree number 171\n",
      "Train mean loss is: 12.951630968416573\n",
      "Test mean loss is: 13.984551435946424\n",
      "Add tree number 172\n",
      "Train mean loss is: 12.94825998113304\n",
      "Test mean loss is: 13.981955695217064\n",
      "Add tree number 173\n",
      "Train mean loss is: 12.941107722001918\n",
      "Test mean loss is: 13.980197610039163\n",
      "Add tree number 174\n",
      "Train mean loss is: 12.935852306248032\n",
      "Test mean loss is: 13.984003178579202\n",
      "Add tree number 175\n",
      "Train mean loss is: 12.928888773346992\n",
      "Test mean loss is: 13.983995687134145\n",
      "Add tree number 176\n",
      "Train mean loss is: 12.923320715728366\n",
      "Test mean loss is: 13.991900737694742\n",
      "Add tree number 177\n",
      "Train mean loss is: 12.918631492106867\n",
      "Test mean loss is: 13.990484246996912\n",
      "Add tree number 178\n",
      "Train mean loss is: 12.917037569254974\n",
      "Test mean loss is: 13.987873215528573\n",
      "Add tree number 179\n",
      "Train mean loss is: 12.910339931424922\n",
      "Test mean loss is: 13.986746367664212\n",
      "Add tree number 180\n",
      "Train mean loss is: 12.904522505870174\n",
      "Test mean loss is: 13.98194260279405\n",
      "Add tree number 181\n",
      "Train mean loss is: 12.903608857271967\n",
      "Test mean loss is: 13.983966019334863\n",
      "Add tree number 182\n",
      "Train mean loss is: 12.897888488624764\n",
      "Test mean loss is: 13.972537747212504\n",
      "Add tree number 183\n",
      "Train mean loss is: 12.892273747308886\n",
      "Test mean loss is: 13.983192983849422\n",
      "Add tree number 184\n",
      "Train mean loss is: 12.888582448791038\n",
      "Test mean loss is: 13.99133741922581\n",
      "Add tree number 185\n",
      "Train mean loss is: 12.884839305001687\n",
      "Test mean loss is: 13.999781462350189\n",
      "Add tree number 186\n",
      "Train mean loss is: 12.875779807927737\n",
      "Test mean loss is: 14.008821758162407\n",
      "Add tree number 187\n",
      "Train mean loss is: 12.872857881467315\n",
      "Test mean loss is: 14.00509436122604\n",
      "Add tree number 188\n",
      "Train mean loss is: 12.869544167278518\n",
      "Test mean loss is: 14.006463038251237\n",
      "Add tree number 189\n",
      "Train mean loss is: 12.866365642879602\n",
      "Test mean loss is: 14.004653426028812\n",
      "Add tree number 190\n",
      "Train mean loss is: 12.859698057864817\n",
      "Test mean loss is: 14.007923644393847\n",
      "Add tree number 191\n",
      "Train mean loss is: 12.855635319732507\n",
      "Test mean loss is: 14.007143884883604\n",
      "Add tree number 192\n",
      "Train mean loss is: 12.852382106116668\n",
      "Test mean loss is: 14.006202584385518\n",
      "Add tree number 193\n",
      "Train mean loss is: 12.849009328471102\n",
      "Test mean loss is: 14.004215588154452\n",
      "Add tree number 194\n",
      "Train mean loss is: 12.845740963762806\n",
      "Test mean loss is: 14.00210484946742\n",
      "Add tree number 195\n",
      "Train mean loss is: 12.842894866714172\n",
      "Test mean loss is: 14.008213404944316\n",
      "Add tree number 196\n",
      "Train mean loss is: 12.839709010870141\n",
      "Test mean loss is: 14.00683306826058\n",
      "Add tree number 197\n",
      "Train mean loss is: 12.837176106840449\n",
      "Test mean loss is: 14.010491905726393\n",
      "Add tree number 198\n",
      "Train mean loss is: 12.835363443125019\n",
      "Test mean loss is: 14.009271421990393\n",
      "Add tree number 199\n",
      "Train mean loss is: 12.831080391502837\n",
      "Test mean loss is: 14.01744154416382\n",
      "Add tree number 200\n",
      "Train mean loss is: 12.825859278990217\n",
      "Test mean loss is: 14.028838402171006\n",
      "Add tree number 201\n",
      "Train mean loss is: 12.822898802702495\n",
      "Test mean loss is: 14.027467018275226\n",
      "Add tree number 202\n",
      "Train mean loss is: 12.818430966763795\n",
      "Test mean loss is: 14.029814798989166\n",
      "Add tree number 203\n",
      "Train mean loss is: 12.814614886555391\n",
      "Test mean loss is: 14.028936068051621\n",
      "Add tree number 204\n",
      "Train mean loss is: 12.810253180296721\n",
      "Test mean loss is: 14.028082085266254\n",
      "Add tree number 205\n",
      "Train mean loss is: 12.806808038900709\n",
      "Test mean loss is: 14.033508452239072\n",
      "Add tree number 206\n",
      "Train mean loss is: 12.802835344019636\n",
      "Test mean loss is: 14.028314610835631\n",
      "Add tree number 207\n",
      "Train mean loss is: 12.798244775038446\n",
      "Test mean loss is: 14.0282441771723\n",
      "Add tree number 208\n",
      "Train mean loss is: 12.79470023989575\n",
      "Test mean loss is: 14.029808030035275\n",
      "Add tree number 209\n",
      "Train mean loss is: 12.790362453049836\n",
      "Test mean loss is: 14.025136049910621\n",
      "Add tree number 210\n",
      "Train mean loss is: 12.78507647911428\n",
      "Test mean loss is: 14.029181606296484\n",
      "Add tree number 211\n",
      "Train mean loss is: 12.781350868383717\n",
      "Test mean loss is: 14.022250765481228\n",
      "Add tree number 212\n",
      "Train mean loss is: 12.778619775133546\n",
      "Test mean loss is: 14.021857607266233\n",
      "Add tree number 213\n",
      "Train mean loss is: 12.774746055344883\n",
      "Test mean loss is: 14.022515025023182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 214\n",
      "Train mean loss is: 12.771323529192838\n",
      "Test mean loss is: 14.034359969032204\n",
      "Add tree number 215\n",
      "Train mean loss is: 12.76779287261882\n",
      "Test mean loss is: 14.035680303845538\n",
      "Add tree number 216\n",
      "Train mean loss is: 12.764717893673062\n",
      "Test mean loss is: 14.036461917823969\n",
      "Add tree number 217\n",
      "Train mean loss is: 12.760739149037924\n",
      "Test mean loss is: 14.042636759775704\n",
      "Add tree number 218\n",
      "Train mean loss is: 12.758037933999983\n",
      "Test mean loss is: 14.039856926205395\n",
      "Add tree number 219\n",
      "Train mean loss is: 12.75593737824303\n",
      "Test mean loss is: 14.04539110099597\n",
      "Add tree number 220\n",
      "Train mean loss is: 12.751512930644502\n",
      "Test mean loss is: 14.041544182961147\n",
      "Add tree number 221\n",
      "Train mean loss is: 12.748922808962615\n",
      "Test mean loss is: 14.04392839829236\n",
      "Add tree number 222\n",
      "Train mean loss is: 12.744312333033326\n",
      "Test mean loss is: 14.037692568474963\n",
      "Add tree number 223\n",
      "Train mean loss is: 12.743446297503422\n",
      "Test mean loss is: 14.036846630149036\n",
      "Add tree number 224\n",
      "Train mean loss is: 12.740957830981937\n",
      "Test mean loss is: 14.038670063352745\n",
      "Add tree number 225\n",
      "Train mean loss is: 12.73881151805396\n",
      "Test mean loss is: 14.040654785462184\n",
      "Add tree number 226\n",
      "Train mean loss is: 12.736643410181852\n",
      "Test mean loss is: 14.039662546350332\n",
      "Add tree number 227\n",
      "Train mean loss is: 12.732618929393993\n",
      "Test mean loss is: 14.04380642199392\n",
      "Add tree number 228\n",
      "Train mean loss is: 12.727739508647726\n",
      "Test mean loss is: 14.045102553351379\n",
      "Add tree number 229\n",
      "Train mean loss is: 12.721446725596358\n",
      "Test mean loss is: 14.048306336419163\n",
      "Add tree number 230\n",
      "Train mean loss is: 12.715745902740958\n",
      "Test mean loss is: 14.04308850973137\n",
      "Add tree number 231\n",
      "Train mean loss is: 12.711382673086174\n",
      "Test mean loss is: 14.050385360254754\n",
      "Add tree number 232\n",
      "Train mean loss is: 12.708888309419525\n",
      "Test mean loss is: 14.048014482594693\n",
      "Add tree number 233\n",
      "Train mean loss is: 12.704861499200748\n",
      "Test mean loss is: 14.04581861647816\n",
      "Add tree number 234\n",
      "Train mean loss is: 12.700491528392304\n",
      "Test mean loss is: 14.04504191211651\n",
      "Add tree number 235\n",
      "Train mean loss is: 12.697991560665905\n",
      "Test mean loss is: 14.04126068492542\n",
      "Add tree number 236\n",
      "Train mean loss is: 12.694281389013733\n",
      "Test mean loss is: 14.047605106972355\n",
      "Add tree number 237\n",
      "Train mean loss is: 12.691288499394972\n",
      "Test mean loss is: 14.05274618952434\n",
      "Add tree number 238\n",
      "Train mean loss is: 12.687617959191178\n",
      "Test mean loss is: 14.048829978789907\n",
      "Add tree number 239\n",
      "Train mean loss is: 12.68275711891199\n",
      "Test mean loss is: 14.047501476609542\n",
      "Add tree number 240\n",
      "Train mean loss is: 12.680528227767308\n",
      "Test mean loss is: 14.052620924634775\n",
      "Add tree number 241\n",
      "Train mean loss is: 12.67053407890082\n",
      "Test mean loss is: 14.064150795483997\n",
      "Add tree number 242\n",
      "Train mean loss is: 12.667060319618912\n",
      "Test mean loss is: 14.072537469225844\n",
      "Add tree number 243\n",
      "Train mean loss is: 12.664665910043388\n",
      "Test mean loss is: 14.070772638196358\n",
      "Add tree number 244\n",
      "Train mean loss is: 12.661802018379053\n",
      "Test mean loss is: 14.073903523714641\n",
      "Add tree number 245\n",
      "Train mean loss is: 12.659181284455679\n",
      "Test mean loss is: 14.07395292669602\n",
      "Add tree number 246\n",
      "Train mean loss is: 12.655717150493329\n",
      "Test mean loss is: 14.074107655687868\n",
      "Add tree number 247\n",
      "Train mean loss is: 12.65061199373365\n",
      "Test mean loss is: 14.077540923993086\n",
      "Add tree number 248\n",
      "Train mean loss is: 12.649063101060424\n",
      "Test mean loss is: 14.077343103264555\n",
      "Add tree number 249\n",
      "Train mean loss is: 12.645923162639683\n",
      "Test mean loss is: 14.075506224924377\n",
      "Add tree number 250\n",
      "Train mean loss is: 12.641963653339685\n",
      "Test mean loss is: 14.07655781838551\n",
      "Add tree number 251\n",
      "Train mean loss is: 12.638342698352998\n",
      "Test mean loss is: 14.081478509171536\n",
      "Add tree number 252\n",
      "Train mean loss is: 12.635311450591797\n",
      "Test mean loss is: 14.08108509943497\n",
      "Add tree number 253\n",
      "Train mean loss is: 12.632897606034216\n",
      "Test mean loss is: 14.079853151788043\n",
      "Add tree number 254\n",
      "Train mean loss is: 12.627908365925723\n",
      "Test mean loss is: 14.08005745526636\n",
      "Add tree number 255\n",
      "Train mean loss is: 12.624642927146006\n",
      "Test mean loss is: 14.086279177458\n",
      "Add tree number 256\n",
      "Train mean loss is: 12.62105832656831\n",
      "Test mean loss is: 14.09523866940986\n",
      "Add tree number 257\n",
      "Train mean loss is: 12.617245157590345\n",
      "Test mean loss is: 14.096132778408075\n",
      "Add tree number 258\n",
      "Train mean loss is: 12.61302535308971\n",
      "Test mean loss is: 14.10477499786531\n",
      "Add tree number 259\n",
      "Train mean loss is: 12.610070876519135\n",
      "Test mean loss is: 14.114702084848007\n",
      "Add tree number 260\n",
      "Train mean loss is: 12.607283341767591\n",
      "Test mean loss is: 14.110976397039014\n",
      "Add tree number 261\n",
      "Train mean loss is: 12.605262651920809\n",
      "Test mean loss is: 14.112092001188161\n",
      "Add tree number 262\n",
      "Train mean loss is: 12.6035562768043\n",
      "Test mean loss is: 14.117721601317097\n",
      "Add tree number 263\n",
      "Train mean loss is: 12.600623458978324\n",
      "Test mean loss is: 14.118338676144791\n",
      "Add tree number 264\n",
      "Train mean loss is: 12.596548076754262\n",
      "Test mean loss is: 14.123129685963073\n",
      "Add tree number 265\n",
      "Train mean loss is: 12.5918584132006\n",
      "Test mean loss is: 14.122703012290389\n",
      "Add tree number 266\n",
      "Train mean loss is: 12.59041676100014\n",
      "Test mean loss is: 14.119499553750043\n",
      "Add tree number 267\n",
      "Train mean loss is: 12.58882690977549\n",
      "Test mean loss is: 14.117610891297712\n",
      "Add tree number 268\n",
      "Train mean loss is: 12.585460626753848\n",
      "Test mean loss is: 14.115099499650896\n",
      "Add tree number 269\n",
      "Train mean loss is: 12.582793713582532\n",
      "Test mean loss is: 14.108882155393697\n",
      "Add tree number 270\n",
      "Train mean loss is: 12.579458467804175\n",
      "Test mean loss is: 14.10422597240482\n",
      "Add tree number 271\n",
      "Train mean loss is: 12.575699435272234\n",
      "Test mean loss is: 14.10264317021877\n",
      "Add tree number 272\n",
      "Train mean loss is: 12.570802651072203\n",
      "Test mean loss is: 14.106178181306513\n",
      "Add tree number 273\n",
      "Train mean loss is: 12.567962832437749\n",
      "Test mean loss is: 14.10647105890995\n",
      "Add tree number 274\n",
      "Train mean loss is: 12.564776830951592\n",
      "Test mean loss is: 14.103850142978827\n",
      "Add tree number 275\n",
      "Train mean loss is: 12.562228563521952\n",
      "Test mean loss is: 14.102651000094236\n",
      "Add tree number 276\n",
      "Train mean loss is: 12.557611864013753\n",
      "Test mean loss is: 14.109985143387046\n",
      "Add tree number 277\n",
      "Train mean loss is: 12.556074658436001\n",
      "Test mean loss is: 14.107218225760493\n",
      "Add tree number 278\n",
      "Train mean loss is: 12.552131655095925\n",
      "Test mean loss is: 14.122869948156962\n",
      "Add tree number 279\n",
      "Train mean loss is: 12.5478340085071\n",
      "Test mean loss is: 14.144657367995817\n",
      "Add tree number 280\n",
      "Train mean loss is: 12.545960275814638\n",
      "Test mean loss is: 14.144371596637383\n",
      "Add tree number 281\n",
      "Train mean loss is: 12.541173022610947\n",
      "Test mean loss is: 14.142640051028476\n",
      "Add tree number 282\n",
      "Train mean loss is: 12.536936037800858\n",
      "Test mean loss is: 14.142539796104487\n",
      "Add tree number 283\n",
      "Train mean loss is: 12.534117736589504\n",
      "Test mean loss is: 14.141690264001896\n",
      "Add tree number 284\n",
      "Train mean loss is: 12.530818821904916\n",
      "Test mean loss is: 14.143775217255993\n",
      "Add tree number 285\n",
      "Train mean loss is: 12.527648804983643\n",
      "Test mean loss is: 14.141025289906892\n",
      "Add tree number 286\n",
      "Train mean loss is: 12.526408202198649\n",
      "Test mean loss is: 14.143370765949278\n",
      "Add tree number 287\n",
      "Train mean loss is: 12.522670622439573\n",
      "Test mean loss is: 14.142511046856134\n",
      "Add tree number 288\n",
      "Train mean loss is: 12.52052992331421\n",
      "Test mean loss is: 14.139491482640468\n",
      "Add tree number 289\n",
      "Train mean loss is: 12.515861757043394\n",
      "Test mean loss is: 14.144227718330429\n",
      "Add tree number 290\n",
      "Train mean loss is: 12.511778928998401\n",
      "Test mean loss is: 14.143145155883348\n",
      "Add tree number 291\n",
      "Train mean loss is: 12.507880878470237\n",
      "Test mean loss is: 14.139275843762112\n",
      "Add tree number 292\n",
      "Train mean loss is: 12.504457770986647\n",
      "Test mean loss is: 14.131491273138948\n",
      "Add tree number 293\n",
      "Train mean loss is: 12.49968600130121\n",
      "Test mean loss is: 14.132524213236588\n",
      "Add tree number 294\n",
      "Train mean loss is: 12.4970647947116\n",
      "Test mean loss is: 14.134086401887847\n",
      "Add tree number 295\n",
      "Train mean loss is: 12.49378982435574\n",
      "Test mean loss is: 14.139820962821627\n",
      "Add tree number 296\n",
      "Train mean loss is: 12.493175868590056\n",
      "Test mean loss is: 14.135345218728725\n",
      "Add tree number 297\n",
      "Train mean loss is: 12.491188823906185\n",
      "Test mean loss is: 14.131341759083671\n",
      "Add tree number 298\n",
      "Train mean loss is: 12.484525266267923\n",
      "Test mean loss is: 14.132892808359957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 299\n",
      "Train mean loss is: 12.48143561053437\n",
      "Test mean loss is: 14.130799737497231\n",
      "Add tree number 300\n",
      "Train mean loss is: 12.477982548783894\n",
      "Test mean loss is: 14.124907365830534\n",
      "Start 3 0.6 50\n",
      "Add tree number 1\n",
      "Train mean loss is: 18.146589436436727\n",
      "Test mean loss is: 17.046017532198412\n",
      "Add tree number 2\n",
      "Train mean loss is: 15.643547353577123\n",
      "Test mean loss is: 14.74753095446224\n",
      "Add tree number 3\n",
      "Train mean loss is: 15.080993039402317\n",
      "Test mean loss is: 14.322259574585312\n",
      "Add tree number 4\n",
      "Train mean loss is: 14.899598930632253\n",
      "Test mean loss is: 14.182956792128689\n",
      "Add tree number 5\n",
      "Train mean loss is: 14.763590136535019\n",
      "Test mean loss is: 14.093365825443847\n",
      "Add tree number 6\n",
      "Train mean loss is: 14.628001710857275\n",
      "Test mean loss is: 14.006491735912917\n",
      "Add tree number 7\n",
      "Train mean loss is: 14.54842588173398\n",
      "Test mean loss is: 13.950992737851744\n",
      "Add tree number 8\n",
      "Train mean loss is: 14.504394876923943\n",
      "Test mean loss is: 13.927642542397162\n",
      "Add tree number 9\n",
      "Train mean loss is: 14.440780410305853\n",
      "Test mean loss is: 13.91151479779792\n",
      "Add tree number 10\n",
      "Train mean loss is: 14.408726345861309\n",
      "Test mean loss is: 13.888282249104682\n",
      "Add tree number 11\n",
      "Train mean loss is: 14.366050325174731\n",
      "Test mean loss is: 13.881569660644754\n",
      "Add tree number 12\n",
      "Train mean loss is: 14.326147667226737\n",
      "Test mean loss is: 13.92256747703201\n",
      "Add tree number 13\n",
      "Train mean loss is: 14.3006774182761\n",
      "Test mean loss is: 13.91564434600816\n",
      "Add tree number 14\n",
      "Train mean loss is: 14.273474040790036\n",
      "Test mean loss is: 13.919216900526393\n",
      "Add tree number 15\n",
      "Train mean loss is: 14.254359518953486\n",
      "Test mean loss is: 13.918578427410045\n",
      "Add tree number 16\n",
      "Train mean loss is: 14.234269758038216\n",
      "Test mean loss is: 13.902210466865032\n",
      "Add tree number 17\n",
      "Train mean loss is: 14.217653184101762\n",
      "Test mean loss is: 13.899207545373947\n",
      "Add tree number 18\n",
      "Train mean loss is: 14.201904574345885\n",
      "Test mean loss is: 13.89837615599119\n",
      "Add tree number 19\n",
      "Train mean loss is: 14.171492259957814\n",
      "Test mean loss is: 13.897786972852321\n",
      "Add tree number 20\n",
      "Train mean loss is: 14.136506040786355\n",
      "Test mean loss is: 13.876016409501382\n",
      "Add tree number 21\n",
      "Train mean loss is: 14.114682787176662\n",
      "Test mean loss is: 13.860394454659549\n",
      "Add tree number 22\n",
      "Train mean loss is: 14.102475057265291\n",
      "Test mean loss is: 13.856808021086726\n",
      "Add tree number 23\n",
      "Train mean loss is: 14.088687705046583\n",
      "Test mean loss is: 13.867060836270612\n",
      "Add tree number 24\n",
      "Train mean loss is: 14.065591175232928\n",
      "Test mean loss is: 13.877679115216905\n",
      "Add tree number 25\n",
      "Train mean loss is: 14.052623704680318\n",
      "Test mean loss is: 13.879365394110328\n",
      "Add tree number 26\n",
      "Train mean loss is: 14.041630027064475\n",
      "Test mean loss is: 13.88090670944751\n",
      "Add tree number 27\n",
      "Train mean loss is: 14.033961608894817\n",
      "Test mean loss is: 13.8927524560666\n",
      "Add tree number 28\n",
      "Train mean loss is: 14.021253966900286\n",
      "Test mean loss is: 13.893250485071302\n",
      "Add tree number 29\n",
      "Train mean loss is: 14.008781245147903\n",
      "Test mean loss is: 13.889764070548487\n",
      "Add tree number 30\n",
      "Train mean loss is: 14.000483125709763\n",
      "Test mean loss is: 13.892357460179865\n",
      "Add tree number 31\n",
      "Train mean loss is: 13.987591658676198\n",
      "Test mean loss is: 13.899592746840547\n",
      "Add tree number 32\n",
      "Train mean loss is: 13.977681637266773\n",
      "Test mean loss is: 13.902335419846283\n",
      "Add tree number 33\n",
      "Train mean loss is: 13.961623651127194\n",
      "Test mean loss is: 13.898329913626496\n",
      "Add tree number 34\n",
      "Train mean loss is: 13.948387154430728\n",
      "Test mean loss is: 13.904608022270972\n",
      "Add tree number 35\n",
      "Train mean loss is: 13.935403548458432\n",
      "Test mean loss is: 13.902837776358462\n",
      "Add tree number 36\n",
      "Train mean loss is: 13.910816193656535\n",
      "Test mean loss is: 13.89438604738719\n",
      "Add tree number 37\n",
      "Train mean loss is: 13.90081034852139\n",
      "Test mean loss is: 13.89429633608265\n",
      "Add tree number 38\n",
      "Train mean loss is: 13.893473627854469\n",
      "Test mean loss is: 13.881273354560156\n",
      "Add tree number 39\n",
      "Train mean loss is: 13.879604464769324\n",
      "Test mean loss is: 13.87129205500226\n",
      "Add tree number 40\n",
      "Train mean loss is: 13.8662972894331\n",
      "Test mean loss is: 13.852819060642213\n",
      "Add tree number 41\n",
      "Train mean loss is: 13.852318529230121\n",
      "Test mean loss is: 13.859104537577323\n",
      "Add tree number 42\n",
      "Train mean loss is: 13.840138311597617\n",
      "Test mean loss is: 13.846884906420758\n",
      "Add tree number 43\n",
      "Train mean loss is: 13.834297990417344\n",
      "Test mean loss is: 13.845986035811395\n",
      "Add tree number 44\n",
      "Train mean loss is: 13.826576731882541\n",
      "Test mean loss is: 13.845816415175413\n",
      "Add tree number 45\n",
      "Train mean loss is: 13.816422389896658\n",
      "Test mean loss is: 13.85836466149014\n",
      "Add tree number 46\n",
      "Train mean loss is: 13.808057662358687\n",
      "Test mean loss is: 13.858617900800535\n",
      "Add tree number 47\n",
      "Train mean loss is: 13.804151783887288\n",
      "Test mean loss is: 13.853419750806289\n",
      "Add tree number 48\n",
      "Train mean loss is: 13.79404285536768\n",
      "Test mean loss is: 13.866536303709978\n",
      "Add tree number 49\n",
      "Train mean loss is: 13.787918832422873\n",
      "Test mean loss is: 13.871228951464126\n",
      "Add tree number 50\n",
      "Train mean loss is: 13.78108133229604\n",
      "Test mean loss is: 13.859350784978808\n",
      "Add tree number 51\n",
      "Train mean loss is: 13.763087364224956\n",
      "Test mean loss is: 13.86861446776557\n",
      "Add tree number 52\n",
      "Train mean loss is: 13.73986249382926\n",
      "Test mean loss is: 13.887551463794681\n",
      "Add tree number 53\n",
      "Train mean loss is: 13.72738356156548\n",
      "Test mean loss is: 13.88198491533898\n",
      "Add tree number 54\n",
      "Train mean loss is: 13.715635982226237\n",
      "Test mean loss is: 13.884759031549644\n",
      "Add tree number 55\n",
      "Train mean loss is: 13.6963878233653\n",
      "Test mean loss is: 13.893609388911738\n",
      "Add tree number 56\n",
      "Train mean loss is: 13.689778538810003\n",
      "Test mean loss is: 13.898084588704927\n",
      "Add tree number 57\n",
      "Train mean loss is: 13.681708426663356\n",
      "Test mean loss is: 13.898476540238141\n",
      "Add tree number 58\n",
      "Train mean loss is: 13.672809722690447\n",
      "Test mean loss is: 13.891366276557516\n",
      "Add tree number 59\n",
      "Train mean loss is: 13.664148077751094\n",
      "Test mean loss is: 13.903314995382335\n",
      "Add tree number 60\n",
      "Train mean loss is: 13.644385163040457\n",
      "Test mean loss is: 13.909692357777322\n",
      "Add tree number 61\n",
      "Train mean loss is: 13.634502127671794\n",
      "Test mean loss is: 13.907728475150067\n",
      "Add tree number 62\n",
      "Train mean loss is: 13.623826592422324\n",
      "Test mean loss is: 13.911387199013353\n",
      "Add tree number 63\n",
      "Train mean loss is: 13.614627762346705\n",
      "Test mean loss is: 13.911344552422479\n",
      "Add tree number 64\n",
      "Train mean loss is: 13.605094471913105\n",
      "Test mean loss is: 13.912736289141062\n",
      "Add tree number 65\n",
      "Train mean loss is: 13.601335889795637\n",
      "Test mean loss is: 13.910883150641677\n",
      "Add tree number 66\n",
      "Train mean loss is: 13.595187351877678\n",
      "Test mean loss is: 13.90322046501374\n",
      "Add tree number 67\n",
      "Train mean loss is: 13.580816575174739\n",
      "Test mean loss is: 13.918040104086836\n",
      "Add tree number 68\n",
      "Train mean loss is: 13.574826377087838\n",
      "Test mean loss is: 13.906633520845977\n",
      "Add tree number 69\n",
      "Train mean loss is: 13.568706880388373\n",
      "Test mean loss is: 13.903960295766227\n",
      "Add tree number 70\n",
      "Train mean loss is: 13.564016408565765\n",
      "Test mean loss is: 13.904197558378716\n",
      "Add tree number 71\n",
      "Train mean loss is: 13.556250756585634\n",
      "Test mean loss is: 13.906214109674526\n",
      "Add tree number 72\n",
      "Train mean loss is: 13.550249187112506\n",
      "Test mean loss is: 13.908080066586693\n",
      "Add tree number 73\n",
      "Train mean loss is: 13.537845942287564\n",
      "Test mean loss is: 13.898273424586309\n",
      "Add tree number 74\n",
      "Train mean loss is: 13.533280041167334\n",
      "Test mean loss is: 13.896353963044154\n",
      "Add tree number 75\n",
      "Train mean loss is: 13.525193878449326\n",
      "Test mean loss is: 13.911772743919707\n",
      "Add tree number 76\n",
      "Train mean loss is: 13.52051090773972\n",
      "Test mean loss is: 13.918854967683052\n",
      "Add tree number 77\n",
      "Train mean loss is: 13.516545098873602\n",
      "Test mean loss is: 13.92361086478539\n",
      "Add tree number 78\n",
      "Train mean loss is: 13.506091810422106\n",
      "Test mean loss is: 13.896480605694489\n",
      "Add tree number 79\n",
      "Train mean loss is: 13.499324716889097\n",
      "Test mean loss is: 13.887990460776605\n",
      "Add tree number 80\n",
      "Train mean loss is: 13.48604496199163\n",
      "Test mean loss is: 13.881513434797549\n",
      "Add tree number 81\n",
      "Train mean loss is: 13.479295356542522\n",
      "Test mean loss is: 13.881690429350657\n",
      "Add tree number 82\n",
      "Train mean loss is: 13.470851674162551\n",
      "Test mean loss is: 13.877825384146979\n",
      "Add tree number 83\n",
      "Train mean loss is: 13.46465354300028\n",
      "Test mean loss is: 13.883224435271059\n",
      "Add tree number 84\n",
      "Train mean loss is: 13.459223942135143\n",
      "Test mean loss is: 13.894638845656534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 85\n",
      "Train mean loss is: 13.445622815981743\n",
      "Test mean loss is: 13.912853941277284\n",
      "Add tree number 86\n",
      "Train mean loss is: 13.439471907787242\n",
      "Test mean loss is: 13.914774628710283\n",
      "Add tree number 87\n",
      "Train mean loss is: 13.433526145991035\n",
      "Test mean loss is: 13.910660846682543\n",
      "Add tree number 88\n",
      "Train mean loss is: 13.425581906860248\n",
      "Test mean loss is: 13.908527126799012\n",
      "Add tree number 89\n",
      "Train mean loss is: 13.412074589234562\n",
      "Test mean loss is: 13.911214352085143\n",
      "Add tree number 90\n",
      "Train mean loss is: 13.405884114561072\n",
      "Test mean loss is: 13.920166249801596\n",
      "Add tree number 91\n",
      "Train mean loss is: 13.396127695999628\n",
      "Test mean loss is: 13.929044848561064\n",
      "Add tree number 92\n",
      "Train mean loss is: 13.390953983446996\n",
      "Test mean loss is: 13.922665097042227\n",
      "Add tree number 93\n",
      "Train mean loss is: 13.383298697360848\n",
      "Test mean loss is: 13.927704478487762\n",
      "Add tree number 94\n",
      "Train mean loss is: 13.375819057417006\n",
      "Test mean loss is: 13.912441340222045\n",
      "Add tree number 95\n",
      "Train mean loss is: 13.367688386460358\n",
      "Test mean loss is: 13.914261044859435\n",
      "Add tree number 96\n",
      "Train mean loss is: 13.362436338521077\n",
      "Test mean loss is: 13.910901266726553\n",
      "Add tree number 97\n",
      "Train mean loss is: 13.356674630695395\n",
      "Test mean loss is: 13.903716237636297\n",
      "Add tree number 98\n",
      "Train mean loss is: 13.348221145672325\n",
      "Test mean loss is: 13.904527608896409\n",
      "Add tree number 99\n",
      "Train mean loss is: 13.34412222336626\n",
      "Test mean loss is: 13.9069274201927\n",
      "Add tree number 100\n",
      "Train mean loss is: 13.33741532322613\n",
      "Test mean loss is: 13.908237605533918\n",
      "Add tree number 101\n",
      "Train mean loss is: 13.333612504138749\n",
      "Test mean loss is: 13.905901884826847\n",
      "Add tree number 102\n",
      "Train mean loss is: 13.328649367048053\n",
      "Test mean loss is: 13.9168810581379\n",
      "Add tree number 103\n",
      "Train mean loss is: 13.325974626644514\n",
      "Test mean loss is: 13.914666610388371\n",
      "Add tree number 104\n",
      "Train mean loss is: 13.319473869522504\n",
      "Test mean loss is: 13.922455906922071\n",
      "Add tree number 105\n",
      "Train mean loss is: 13.3136542731424\n",
      "Test mean loss is: 13.92266961931786\n",
      "Add tree number 106\n",
      "Train mean loss is: 13.308630422726612\n",
      "Test mean loss is: 13.929845115198411\n",
      "Add tree number 107\n",
      "Train mean loss is: 13.30381121853005\n",
      "Test mean loss is: 13.932558932837404\n",
      "Add tree number 108\n",
      "Train mean loss is: 13.298415021244558\n",
      "Test mean loss is: 13.933626920239014\n",
      "Add tree number 109\n",
      "Train mean loss is: 13.292384346923848\n",
      "Test mean loss is: 13.951764956726041\n",
      "Add tree number 110\n",
      "Train mean loss is: 13.287549976269752\n",
      "Test mean loss is: 13.951589694312693\n",
      "Add tree number 111\n",
      "Train mean loss is: 13.285123956338023\n",
      "Test mean loss is: 13.950220754001421\n",
      "Add tree number 112\n",
      "Train mean loss is: 13.27775586941932\n",
      "Test mean loss is: 13.947210955854791\n",
      "Add tree number 113\n",
      "Train mean loss is: 13.26783322980713\n",
      "Test mean loss is: 13.948358998643664\n",
      "Add tree number 114\n",
      "Train mean loss is: 13.262684092160448\n",
      "Test mean loss is: 13.945529658395264\n",
      "Add tree number 115\n",
      "Train mean loss is: 13.25586669964425\n",
      "Test mean loss is: 13.959641400520665\n",
      "Add tree number 116\n",
      "Train mean loss is: 13.251517512928961\n",
      "Test mean loss is: 13.964429756406908\n",
      "Add tree number 117\n",
      "Train mean loss is: 13.246043028197375\n",
      "Test mean loss is: 13.948329672150129\n",
      "Add tree number 118\n",
      "Train mean loss is: 13.240467818340386\n",
      "Test mean loss is: 13.946862575353837\n",
      "Add tree number 119\n",
      "Train mean loss is: 13.23614570561522\n",
      "Test mean loss is: 13.950783263316772\n",
      "Add tree number 120\n",
      "Train mean loss is: 13.231451371207433\n",
      "Test mean loss is: 13.960941151803729\n",
      "Add tree number 121\n",
      "Train mean loss is: 13.22097438632241\n",
      "Test mean loss is: 13.971047100016488\n",
      "Add tree number 122\n",
      "Train mean loss is: 13.20891615759005\n",
      "Test mean loss is: 13.97052355977642\n",
      "Add tree number 123\n",
      "Train mean loss is: 13.205870431049513\n",
      "Test mean loss is: 13.98059686606052\n",
      "Add tree number 124\n",
      "Train mean loss is: 13.199179469357814\n",
      "Test mean loss is: 13.98873080771681\n",
      "Add tree number 125\n",
      "Train mean loss is: 13.19106783625683\n",
      "Test mean loss is: 13.987674519642669\n",
      "Add tree number 126\n",
      "Train mean loss is: 13.185505207954188\n",
      "Test mean loss is: 13.982795533369622\n",
      "Add tree number 127\n",
      "Train mean loss is: 13.181782868697406\n",
      "Test mean loss is: 13.987345069827876\n",
      "Add tree number 128\n",
      "Train mean loss is: 13.174416427421233\n",
      "Test mean loss is: 13.97734021409153\n",
      "Add tree number 129\n",
      "Train mean loss is: 13.165396674707363\n",
      "Test mean loss is: 13.999968125591606\n",
      "Add tree number 130\n",
      "Train mean loss is: 13.16166489995961\n",
      "Test mean loss is: 14.00066584029908\n",
      "Add tree number 131\n",
      "Train mean loss is: 13.154329063308968\n",
      "Test mean loss is: 13.99756136503639\n",
      "Add tree number 132\n",
      "Train mean loss is: 13.145059862644615\n",
      "Test mean loss is: 13.993623396984262\n",
      "Add tree number 133\n",
      "Train mean loss is: 13.136940461815517\n",
      "Test mean loss is: 13.993211190522088\n",
      "Add tree number 134\n",
      "Train mean loss is: 13.133107384452225\n",
      "Test mean loss is: 13.99248136847781\n",
      "Add tree number 135\n",
      "Train mean loss is: 13.129157151418973\n",
      "Test mean loss is: 13.993595009478181\n",
      "Add tree number 136\n",
      "Train mean loss is: 13.125041614970609\n",
      "Test mean loss is: 13.987437278317882\n",
      "Add tree number 137\n",
      "Train mean loss is: 13.122294089394849\n",
      "Test mean loss is: 13.991700202703374\n",
      "Add tree number 138\n",
      "Train mean loss is: 13.11269915224477\n",
      "Test mean loss is: 13.991948397976913\n",
      "Add tree number 139\n",
      "Train mean loss is: 13.108842547322666\n",
      "Test mean loss is: 13.996821272188921\n",
      "Add tree number 140\n",
      "Train mean loss is: 13.10488906177847\n",
      "Test mean loss is: 14.003008133950757\n",
      "Add tree number 141\n",
      "Train mean loss is: 13.100829247551513\n",
      "Test mean loss is: 14.00167689813166\n",
      "Add tree number 142\n",
      "Train mean loss is: 13.095702948767302\n",
      "Test mean loss is: 14.00259404769743\n",
      "Add tree number 143\n",
      "Train mean loss is: 13.085530060662434\n",
      "Test mean loss is: 14.002634156699745\n",
      "Add tree number 144\n",
      "Train mean loss is: 13.074821570752032\n",
      "Test mean loss is: 14.004398199313348\n",
      "Add tree number 145\n",
      "Train mean loss is: 13.070177448473375\n",
      "Test mean loss is: 14.013267478617012\n",
      "Add tree number 146\n",
      "Train mean loss is: 13.06483582464628\n",
      "Test mean loss is: 14.015318692283795\n",
      "Add tree number 147\n",
      "Train mean loss is: 13.061255846933747\n",
      "Test mean loss is: 14.011531121468334\n",
      "Add tree number 148\n",
      "Train mean loss is: 13.057827736049513\n",
      "Test mean loss is: 14.01232071454731\n",
      "Add tree number 149\n",
      "Train mean loss is: 13.052017909736072\n",
      "Test mean loss is: 14.030294709820883\n",
      "Add tree number 150\n",
      "Train mean loss is: 13.048509248026175\n",
      "Test mean loss is: 14.024857504526855\n",
      "Add tree number 151\n",
      "Train mean loss is: 13.045814709062912\n",
      "Test mean loss is: 14.025325730260562\n",
      "Add tree number 152\n",
      "Train mean loss is: 13.043470874276695\n",
      "Test mean loss is: 14.022510799723669\n",
      "Add tree number 153\n",
      "Train mean loss is: 13.040147811950527\n",
      "Test mean loss is: 14.022918902670165\n",
      "Add tree number 154\n",
      "Train mean loss is: 13.03790570215692\n",
      "Test mean loss is: 14.016753379804976\n",
      "Add tree number 155\n",
      "Train mean loss is: 13.034351800859485\n",
      "Test mean loss is: 14.020356090259607\n",
      "Add tree number 156\n",
      "Train mean loss is: 13.031959732067934\n",
      "Test mean loss is: 14.018166849973321\n",
      "Add tree number 157\n",
      "Train mean loss is: 13.02736530266441\n",
      "Test mean loss is: 14.019569019977487\n",
      "Add tree number 158\n",
      "Train mean loss is: 13.02243639472414\n",
      "Test mean loss is: 14.02840037242128\n",
      "Add tree number 159\n",
      "Train mean loss is: 13.009387461223335\n",
      "Test mean loss is: 14.019743667749237\n",
      "Add tree number 160\n",
      "Train mean loss is: 13.00426202597715\n",
      "Test mean loss is: 14.024129206036244\n",
      "Add tree number 161\n",
      "Train mean loss is: 13.001585737700037\n",
      "Test mean loss is: 14.033839732161116\n",
      "Add tree number 162\n",
      "Train mean loss is: 12.99542302915185\n",
      "Test mean loss is: 14.03993429937039\n",
      "Add tree number 163\n",
      "Train mean loss is: 12.989262684701725\n",
      "Test mean loss is: 14.061727318483351\n",
      "Add tree number 164\n",
      "Train mean loss is: 12.983509457456089\n",
      "Test mean loss is: 14.074022168862621\n",
      "Add tree number 165\n",
      "Train mean loss is: 12.975540689940349\n",
      "Test mean loss is: 14.070474766657206\n",
      "Add tree number 166\n",
      "Train mean loss is: 12.968562714878775\n",
      "Test mean loss is: 14.068543731570122\n",
      "Add tree number 167\n",
      "Train mean loss is: 12.963923292189362\n",
      "Test mean loss is: 14.07439917669995\n",
      "Add tree number 168\n",
      "Train mean loss is: 12.960238000656146\n",
      "Test mean loss is: 14.07326828048481\n",
      "Add tree number 169\n",
      "Train mean loss is: 12.954198915189913\n",
      "Test mean loss is: 14.075687966930882\n",
      "Add tree number 170\n",
      "Train mean loss is: 12.94872338156818\n",
      "Test mean loss is: 14.079460093763085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add tree number 171\n",
      "Train mean loss is: 12.945566136879002\n",
      "Test mean loss is: 14.074369692612864\n",
      "Add tree number 172\n",
      "Train mean loss is: 12.940704285360965\n",
      "Test mean loss is: 14.071074412208146\n",
      "Add tree number 173\n",
      "Train mean loss is: 12.937525470116558\n",
      "Test mean loss is: 14.070389736532661\n",
      "Add tree number 174\n",
      "Train mean loss is: 12.93336345106652\n",
      "Test mean loss is: 14.0691487821142\n",
      "Add tree number 175\n",
      "Train mean loss is: 12.931287228967959\n",
      "Test mean loss is: 14.06211868103694\n",
      "Add tree number 176\n",
      "Train mean loss is: 12.928426564498183\n",
      "Test mean loss is: 14.056805304791217\n",
      "Add tree number 177\n",
      "Train mean loss is: 12.924560654290252\n",
      "Test mean loss is: 14.055070136044732\n",
      "Add tree number 178\n",
      "Train mean loss is: 12.920709579258073\n",
      "Test mean loss is: 14.052984781879905\n",
      "Add tree number 179\n",
      "Train mean loss is: 12.915901269487021\n",
      "Test mean loss is: 14.049120216031397\n",
      "Add tree number 180\n",
      "Train mean loss is: 12.91236872573922\n",
      "Test mean loss is: 14.051971097703042\n",
      "Add tree number 181\n",
      "Train mean loss is: 12.908555819699608\n",
      "Test mean loss is: 14.047625690097782\n",
      "Add tree number 182\n",
      "Train mean loss is: 12.90217283147234\n",
      "Test mean loss is: 14.053374200976243\n",
      "Add tree number 183\n",
      "Train mean loss is: 12.897983332733117\n",
      "Test mean loss is: 14.06314033865849\n",
      "Add tree number 184\n",
      "Train mean loss is: 12.895294149558845\n",
      "Test mean loss is: 14.064364736261686\n",
      "Add tree number 185\n",
      "Train mean loss is: 12.891506490285849\n",
      "Test mean loss is: 14.0649960094246\n",
      "Add tree number 186\n",
      "Train mean loss is: 12.887132323040538\n",
      "Test mean loss is: 14.057691170903565\n",
      "Add tree number 187\n",
      "Train mean loss is: 12.87875682922892\n",
      "Test mean loss is: 14.065960501339273\n",
      "Add tree number 188\n",
      "Train mean loss is: 12.873814446744461\n",
      "Test mean loss is: 14.064558891851844\n",
      "Add tree number 189\n",
      "Train mean loss is: 12.869728055728858\n",
      "Test mean loss is: 14.06925277591154\n",
      "Add tree number 190\n",
      "Train mean loss is: 12.866134267619467\n",
      "Test mean loss is: 14.07090368938358\n",
      "Add tree number 191\n",
      "Train mean loss is: 12.860568387922708\n",
      "Test mean loss is: 14.073007602031193\n",
      "Add tree number 192\n",
      "Train mean loss is: 12.856935836346976\n",
      "Test mean loss is: 14.080300035110225\n",
      "Add tree number 193\n",
      "Train mean loss is: 12.851941301903251\n",
      "Test mean loss is: 14.087565939458756\n",
      "Add tree number 194\n",
      "Train mean loss is: 12.84878043915574\n",
      "Test mean loss is: 14.088094890808273\n",
      "Add tree number 195\n",
      "Train mean loss is: 12.844974885825327\n",
      "Test mean loss is: 14.089355972474772\n",
      "Add tree number 196\n",
      "Train mean loss is: 12.840549265354616\n",
      "Test mean loss is: 14.093698036759585\n",
      "Add tree number 197\n",
      "Train mean loss is: 12.837126460225306\n",
      "Test mean loss is: 14.094886418549095\n",
      "Add tree number 198\n",
      "Train mean loss is: 12.833963019723516\n",
      "Test mean loss is: 14.096134557532151\n",
      "Add tree number 199\n",
      "Train mean loss is: 12.824638384843782\n",
      "Test mean loss is: 14.10527360574496\n",
      "Add tree number 200\n",
      "Train mean loss is: 12.823196887103691\n",
      "Test mean loss is: 14.111773514286236\n",
      "Add tree number 201\n",
      "Train mean loss is: 12.819052960686909\n",
      "Test mean loss is: 14.104782730776211\n",
      "Add tree number 202\n",
      "Train mean loss is: 12.81611845555139\n",
      "Test mean loss is: 14.103973555275246\n",
      "Add tree number 203\n",
      "Train mean loss is: 12.813812700373662\n",
      "Test mean loss is: 14.10495046124789\n",
      "Add tree number 204\n",
      "Train mean loss is: 12.810638649766798\n",
      "Test mean loss is: 14.105957714342964\n",
      "Add tree number 205\n",
      "Train mean loss is: 12.806698812987177\n",
      "Test mean loss is: 14.104413362991398\n",
      "Add tree number 206\n",
      "Train mean loss is: 12.802730764872175\n",
      "Test mean loss is: 14.111536305467022\n",
      "Add tree number 207\n",
      "Train mean loss is: 12.796835127434637\n",
      "Test mean loss is: 14.10811823478305\n"
     ]
    }
   ],
   "source": [
    "models_data = {}\n",
    "\n",
    "params_list = []\n",
    "\n",
    "weight_decay_list = [0.1, 0.3, 0.6, 0.9]\n",
    "for weight_decay in weight_decay_list:\n",
    "    params = HParams(num_trees=300, max_depth=3, min_node_size=0, \n",
    "                     weight_decay=weight_decay, sub_samp=0.7, verbose=1, num_thresholds=20)\n",
    "    params_list.append(params)\n",
    "    \n",
    "num_thresh_list = [10, 30, 50]\n",
    "for num_thresh in num_thresh_list:\n",
    "    params = HParams(num_trees=300, max_depth=3, min_node_size=0, \n",
    "                     weight_decay=0.6, sub_samp=0.7, verbose=1, num_thresholds=num_thresh)\n",
    "    params_list.append(params)\n",
    "\n",
    "max_depth_list = [1, 5, 7]\n",
    "for max_depth in max_depth_list:\n",
    "    params = HParams(num_trees=300, max_depth=max_depth, min_node_size=0, \n",
    "                     weight_decay=0.6, sub_samp=0.7, verbose=1, num_thresholds=20)\n",
    "    params_list.append(params)\n",
    "\n",
    "\n",
    "for params in params_list:\n",
    "    print('Start {} {} {}'.format(params.max_depth, params.weight_decay, params.num_thresholds))\n",
    "\n",
    "    _, model_log = gbrt(train_data=train_dataset.data, test_data=test_dataset.data, \n",
    "                   label_name=train_dataset.label_name, params=params)\n",
    "\n",
    "    models_data[(depth, weight_decay, num_thresh)] = model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2 - Learning Curves with different parameter values\n",
    "\n",
    "Hyperparams impact on error analysis. Here we plot train and test error as a function\n",
    "of the number of trees in the ensemble. \n",
    "\n",
    "We compare plots for different values of Max Depth, Num Thresholds and Learning Rate.\n",
    "\n",
    "Each time we vary one parameter, all other get the following values:\n",
    "    <br>Learning Rate=0.6\n",
    "    <br>Num Thresholds=20 \n",
    "    <br>Min Node Size=0\n",
    "    <br>Sub Sample=0.7 \n",
    "    <br>Max Depth=3\n",
    "\n",
    "All models were trained for 300 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Max Depth\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Training Plots, Changing Max Depth Values\\n Learning Rate - 0.6, Num Thresholds - 20, Min Node Size - 0, Sub Sample - 0.7')\n",
    "tups=[(1, 0.6, 20), (3, 0.6, 20), (5, 0.6, 20), (7, 0.6, 20)]\n",
    "for ind, tup in enumerate(tups):\n",
    "    plt.subplot(2, 2, ind+1)\n",
    "    \n",
    "    plt.title('max depth - {}'.format(tup[0]))\n",
    "\n",
    "    tr = grid_search_data[tup]['train_loss']\n",
    "    te = grid_search_data[tup]['test_loss']\n",
    "    plt.plot(range(len(tr)), tr, c='red', label='Train')\n",
    "    plt.plot(range(len(te)), te, c='blue', label='Test')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    if ind % 2 == 0:\n",
    "        plt.ylabel('Mean Loss')\n",
    "    if ind > 1:\n",
    "        plt.xlabel('Number of Trees')    \n",
    "plt.show()\n",
    "\n",
    "# Changing Num Thresholds\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Training Plots, Changing Num Thresholds Values\\n Learning Rate - 0.6, Max Depth - 3, Min Node Size - 0, Sub Sample - 0.7')\n",
    "tups=[(3, 0.6, 10), (3, 0.6, 20), (3, 0.6, 30), (3, 0.6, 50)]\n",
    "for ind, tup in enumerate(tups):\n",
    "    plt.subplot(2, 2, ind+1)\n",
    "    \n",
    "    plt.title('num thresholds - {}'.format(tup[2]))\n",
    "\n",
    "    tr = grid_search_data[tup]['train_loss']\n",
    "    te = grid_search_data[tup]['test_loss']\n",
    "    plt.plot(range(len(tr)), tr, c='red', label='Train')\n",
    "    plt.plot(range(len(te)), te, c='blue', label='Test')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    if ind % 2 == 0:\n",
    "        plt.ylabel('Mean Loss')\n",
    "    if ind > 1:\n",
    "        plt.xlabel('Number of Trees')    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Training Plots, Changing Learning Rate Values\\n Max Depth - 3, Num Thresholds - 20, Min Node Size - 0, Sub Sample - 0.7')\n",
    "tups=[(3, 0.1, 20), (3, 0.3, 20), (3, 0.6, 20), (3, 0.9, 20)]\n",
    "for ind, tup in enumerate(tups):\n",
    "    plt.subplot(2, 2, ind+1)\n",
    "    \n",
    "    plt.title('Learning Rate - {}'.format(tup[1]))\n",
    "\n",
    "    tr = grid_search_data[tup]['train_loss']\n",
    "    te = grid_search_data[tup]['test_loss']\n",
    "    plt.plot(range(len(tr)), tr, c='red', label='Train')\n",
    "    plt.plot(range(len(te)), te, c='blue', label='Test')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    if ind % 2 == 0:\n",
    "        plt.ylabel('Mean Loss')\n",
    "    if ind > 1:\n",
    "        plt.xlabel('Number of Trees')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 3 - Training time plots\n",
    "\n",
    "Hyperparams impact on runtime analysis. Here we Plot the time it takes to train a\n",
    "boosted tree ensemble with 300 trees as function of hyperparameters. \n",
    "We chose to show plots varying the Max Depth and The Num Thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tups=[(3, 0.6, 10), (3, 0.6, 20), (3, 0.6, 30), (3, 0.6, 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
